{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tema 4: Redes Neuronales</h1>\n",
    "    <h1>Redes Neuronales 2</h1>\n",
    "    <br>\n",
    "    <h5>Prof. Wladimir Rodr铆guez</h5>\n",
    "    <h5>wladimir@ula.ve</h5>\n",
    "    <h5>Departamento de Computaci贸n</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de las Redes Neuronales: Propagaci贸n Hacia Atr谩s \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n se explicaran los conceptos de la funci贸n de costo log铆stico y el algoritmo de propagaci贸n hacia atr谩s \"Backpropagation\" que se implemantaron en la clase anterior para aprender los pesos de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la funci贸n de costo log铆stico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que se implement贸 el Perceptron Multicapa para realizar clasificaci贸n m煤ltiple, la salida es un vector de $t$ elementos usando la codificaci贸n \"one-hot\", por ejemplo la salida de la capa de salida para un ejemplo de la clase 2:\n",
    "\n",
    "$$a^{(salida)}=\\left[\\\n",
    "\\begin{array}{ll}\n",
    "      0.1 \\\\\n",
    "      0.9 \\\\\n",
    "      \\vdots \\\\\n",
    "      0.3 \\\\\n",
    "\\end{array} \n",
    "\\right], \\ y = \\left[\\\n",
    "\\begin{array}{ll}\n",
    "      0 \\\\\n",
    "      1 \\\\\n",
    "      \\vdots \\\\\n",
    "      0 \\\\\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "Por lo que es necesario generalizar la funci贸n de costo log铆stico a todas las $t$ unidades de activaci贸n de la red. Por lo que la funci贸n de costo es:\n",
    "\n",
    "$$L(\\boldsymbol{W})=\\frac{1}{n}\\sum_{1}^{n}\\sum_{j=1}^{t}(y^{[i]}_j - a_j^{(salida)[i]})^2$$\n",
    "\n",
    "Recordar que nuestro objetivo es minimizar la funci贸n de costo $L(\\boldsymbol{W})$; por lo tanto, se necesita calcular la derivada parcial de los par谩metros $\\boldsymbol{W}$ con respecto a cada peso para cada capa en la red:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w_{j,l}^{(l)}}L(\\boldsymbol{W})$$\n",
    "\n",
    "A continuaci贸n, se presenta el algoritmo de propagaci贸n hacia atr谩s \"backpropagation\", que permite calcular esas derivadas parciales para minimizar la funci贸n de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Propagaci贸n Hacia Atr谩s \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esencia, podemos pensar en la propagaci贸n hacia atr谩s \"backpropagation\" como un enfoque computacionalmente muy eficiente para calcular las derivadas parciales de una funci贸n de costo compleja en redes neuronales multicapa. Aqu铆, nuestro objetivo es usar esas derivadas\n",
    "para aprender los coeficientes de peso para parametrizar una red neuronal multicapa.\n",
    "\n",
    "El desaf铆o en la parametrizaci贸n de redes neuronales es que se esta t铆picamente tratando con una gran cantidad de coeficientes de peso en un espacio de atributos de muchas dimensiones. En contraste con las funciones de costo de neuronales de una sola capa\n",
    "redes como Adaline o regresi贸n log铆stica, la superficie de error de una funci贸n de costo de una red neuronal no es convexa o lisa con respecto a los par谩metros. Hay muchos baches en esta superficie de costo multi-dimensional (m铆nimos locales) que tenemos que superar para encontrar el m铆nimo de la funci贸n de costo.\n",
    "\n",
    "La regla de la cadena es un enfoque para calcular la derivada de una funci贸n anidada compleja, como $f(g(x))$, de la siguiente manera:\n",
    "\n",
    "$$\\frac{d}{dx}[f(g(x))]=\\frac{df}{dx}\\cdot\\frac{dg}{dx}$$\n",
    "\n",
    "De manera similar, se puede usar la regla de cadena para una composici贸n de funci贸n arbitrariamente larga. Por ejemplo, supongamos que tenemos cinco funciones diferentes, $f(x)$, $g(x)$, $h(x)$, $u(x)$ y $v(x)$, y que $F$ sea la composici贸n de la funci贸n: $F(x) = f(g(h(u(v(x)))))$. Aplicando la regla de cadena, podemos calcular la derivada de esta funci贸n de la siguiente manera:\n",
    "\n",
    "$$\\frac{dF}{dx}=\\frac{d}{dx}F(x)=\\frac{d}{dx}f(g(h(u(v(x)))))=\\frac{df}{dg}\\cdot\\frac{dg}{dh}\\cdot\\frac{dh}{du}\\cdot\\frac{du}{dv}\\cdot\\frac{dv}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando  Redes Neuronales usando Propagaci贸n Hacia Atr谩s \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci贸n, explicaremos la matem谩tica de propagaci贸n hacia atr谩s \"backpropagation\" para entender c贸mo se pueden aprender los pesos en una red neuronal de manera muy eficiente.\n",
    "\n",
    "Anteriormente vimos como calcular el costo como la diferencia entre la activaci贸n de la capa de salida y y la etiqueta de clase objetivo. Ahora veremos como trabaja el algoritmo de propagaci贸n hacia atr谩s para actualizar los pesos en nuestro modelo de Perceptr贸n Multicapa. \n",
    "\n",
    "Primero necesitamos aplicar la propagaci贸n hacia adelante para obtener la activaci贸n de la capa de salida, que formulamos de la siguiente manera:\n",
    "\n",
    "$$\\boldsymbol{Z}^{(oculta)}=\\boldsymbol{A}^{(entrada)}\\boldsymbol{W}^{(oculta)T}\\ \\ (entrada\\ a\\ la\\ capa\\ oculta)$$\n",
    "\n",
    "$$\\boldsymbol{A}^{(oculta)}=\\phi(\\boldsymbol{Z}^{(oculta)})\\ \\ (activaci贸n\\ de\\ la\\ capa\\ oculta)$$\n",
    "\n",
    "$$\\boldsymbol{Z}^{(salida)}=\\boldsymbol{A}^{(oculta)}\\boldsymbol{W}^{(salida)T}\\ \\ (entrada\\ a\\ la\\ capa\\ de \\ salida)$$\n",
    "\n",
    "$$\\boldsymbol{A}^{(salida)}=\\phi(\\boldsymbol{Z}^{(salida)})\\ \\ (activaci贸n\\ de\\ la\\ capa\\ \\ de\\ salida)$$\n",
    "\n",
    "La siguiente figura muestra este proceso:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation.png\" width=\"75%\">\n",
    "\n",
    "En propagaci贸n hacia atr谩s, propagamos el error de derecha a izquierda. Podemos pensar en esto como una aplicaci贸n de la regla de la cadena al c谩lculo de la propagaci贸n hacia adelante para calcular el gradiente de la p茅rdida con respecto a los pesos del modelo (y las unidades de sesgo). Para simplificar, ilustraremos este proceso para la derivada parcial utilizada para actualizar el primer peso en la matriz de peso de la capa de salida. Las rutas del c谩lculo que propagamos hacia atr谩s se resaltan mediante las flechas en negrita a continuaci贸n:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation_2.png\" width=\"75%\">\n",
    "\n",
    "El gradiente para el peso $ w_{1,1}^{(s)}$ de la capa de salida:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "Si incluimos la entrada $z$ a la neurona:\n",
    "\n",
    "<img src=\"../figuras/neurona_expandida.png\" width=\"25%\">\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "Para calcular esta derivada parcial, comenzaremos con $\\frac{\\partial L}{\\partial a_1^{(s)}}$, que es la derivada parcial de la funci贸n de perdida MSE.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_1^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}(y_1 - a_1^{(s)})^2 = 2( a_1^{(s)} - y)$$\n",
    "\n",
    "El pr贸ximo t茅rmino es la derivada de la funci贸n de activaci贸n log铆stica que se usa en la capa de salida:\n",
    "\n",
    "$$\\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}} = \\frac{\\partial}{\\partial z_1^{(s)}} \\frac{1}{1 + e^{z_1^{(s)}}} = \\cdots = \\left(\\frac{1}{1 + e^{z_1^{(s)}}}\\right) \\left(1 - \\frac{1}{1 + e^{z_1^{(s)}}}\\right)$$\n",
    "\n",
    "$$= a_1^{(s)}(1 - a_1^{(s)})$$\n",
    "\n",
    "Por 煤ltimo, calculamos la derivada de la entrada con respecto al peso:\n",
    "\n",
    "$$\\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial}{\\partial w_{1,1}^{(s)}}a_1^{(o)}w_{1,1}^{(s)} + b_1^{(s)} = a_1^{(o)}$$\n",
    "\n",
    "Poniendo todo junto, obtenemos lo siguiente:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}} = 2( a_1^{(s)} - y) \\cdot a_1^{(s)}(1 - a_1^{(s)}) \\cdot a_1^{(o)}$$\n",
    "\n",
    "Luego usamos este valor para actualizar el peso a trav茅s de la conocida actualizaci贸n de descenso de gradiente estoc谩stico con una tasa de aprendizaje de :\n",
    "\n",
    "$$w_{1,1}^{(s)} = w_{1,1}^{(s)} - \\eta \\frac{\\partial L}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "A continuacion se ilustra c贸mo calcular la derivada parcial de la p茅rdida con respecto al primer peso de la capa oculta:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation_3.png\" width=\"75%\">\n",
    "\n",
    "Es importante resaltar que dado que el peso $w_{1,1}^{(o)}$ est谩 conectado a ambos nodos de salida, tenemos que usar la regla de la cadena multivariable para sumar las dos rutas resaltadas con flechas en negrita.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(o)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial a_1^{(o)}} \\cdot \\frac{\\partial a_1^{(o)}}{\\partial z_1^{(o)}} \\cdot \\frac{\\partial z_1^{(o)}}{\\partial w_{1,1}^{(o)}}\\\\\n",
    "\\qquad \\; + \\frac{\\partial L}{\\partial a_2^{(s)}}\\cdot \\frac{\\partial a_2^{(s)}}{\\partial z_2^{(s)}}\\cdot \\frac{\\partial z_2^{(s)}}{\\partial a_1^{(o)}} \\cdot \\frac{\\partial a_1^{(o)}}{\\partial z_1^{(o)}} \\cdot \\frac{\\partial z_1^{(o)}}{\\partial w_{1,1}^{(o)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo:\n",
    "\n",
    "### Descripci贸n general\n",
    "\n",
    "Para este ejemplo, vamos a utilizar una red neuronal con dos entradas, dos neuronas ocultas, dos neuronas de salida. Adem谩s, las neuronas ocultas y de salida incluir谩n un sesgo.\n",
    "\n",
    "Esta es la estructura b谩sica:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_1.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Para tener algunos n煤meros con los que trabajar, aqu铆 est谩n los pesos iniciales, los sesgos y las entradas/salidas de entrenamiento:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_2.png\" width=\"50%\">   \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagaci贸n hacia Adelante\n",
    "\n",
    "As铆 es como calculamos la entrada neta total para $o_1$:\n",
    "\n",
    "$net_{o1} = w_1 * e_1 + w_2 * e_2 + b_1 * 1$\n",
    "\n",
    "$net_{o1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775$\n",
    "\n",
    "Luego aplicamos la funci贸n de activaci贸n log铆stica para obtener el resultado de $o_1$:\n",
    "\n",
    "$salida_{o1} = \\frac{1}{1+e^{-net_{o1}}} = \\frac{1}{1+e^{-0.3775}} = 0.593269992$\n",
    "\n",
    "Realizando el mismo proceso para $o_2$ obtenemos:\n",
    "\n",
    "$salida_{o2} = 0.596884378$\n",
    "\n",
    "Repetimos este proceso para las neuronas de la capa de salida, usando la salida de las neuronas de la capa oculta como entradas.\n",
    "\n",
    "Aqu铆 est谩 la salida para $s_1$:\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$net_{s1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967$\n",
    "\n",
    "$salida_{s1} = \\frac{1}{1+e^{-net_{o1}}} = \\frac{1}{1+e^{-1.105905967}} = 0.75136507$\n",
    "\n",
    "Realizando el mismo proceso para $s_2$ obtenemos:\n",
    "\n",
    "$salida_{s2} = 0.772928465$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular el Error Total\n",
    "\n",
    "Ahora podemos calcular el error de cada neurona de salida usando la funci贸n de error al cuadrado y sumarlos para obtener el error total:\n",
    "\n",
    "$E_{total} = \\sum \\frac{1}{2}(objetivo - salida)^{2}$\n",
    "\n",
    "Por ejemplo, la salida objetivo para $s_1$ es $0.01$ pero la salida de la red neuronal es $0.75136507$, por lo que su error es:\n",
    "\n",
    "$E_{s1} = \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2} = \\frac{1}{2}(0.01 - 0.75136507)^{2} = 0.274811083$\n",
    "\n",
    "Repitiendo este proceso para $s_2$ (recordando que el objetivo es 0.99) obtenemos:\n",
    "\n",
    "$E_{s2} = 0.023560026$\n",
    "\n",
    "El error total de la red neuronal es la suma de estos errores:\n",
    "\n",
    "$E_{total} = E_{s1} + E_{s2} = 0.274811083 + 0.023560026 = 0.298371109$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Propagaci贸n hacias Atr谩s\n",
    "\n",
    "Nuestro objetivo con la propagaci贸n hacia atr谩s es actualizar cada uno de los pesos en la red para que hagan que la salida real est茅 m谩s cerca de la salida objetivo, minimizando as铆 el error para cada neurona de salida y la red como un todo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capa de salida\n",
    "\n",
    "Considere $w_5$. Queremos saber cu谩nto afecta un cambio en $w_5$ al error total, tambi茅n conocido como $\\frac{\\partial E_{total}}{\\partial w_{5}}$\n",
    "\n",
    "Aplicando la regla de la cadena sabemos que:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = \\frac{\\partial E_{total}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial w_{5}}$\n",
    "\n",
    "Visualmente, esto es lo que estamos haciendo:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_3.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Tenemos que averiguar cada pieza en esta ecuaci贸n.\n",
    "\n",
    "Primero, 驴cu谩nto cambia el error total con respecto a la salida?\n",
    "\n",
    "$E_{total} = \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2} + \\frac{1}{2}(objetivo_{s2} - salida_{s2})^{2}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{s1}} = 2 * \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2 - 1} * -1 + 0$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{s1}} = -(objetivo_{s1} - salida_{s1}) = -(0.01 - 0.75136507) = 0.74136507$\n",
    "\n",
    "Luego, 驴cu谩nto cambia la salida de $s_1$ con respecto a su entrada neta total?\n",
    "\n",
    "La derivada parcial de la funci贸n log铆stica es la salida multiplicada por 1 menos la salida:\n",
    "\n",
    "$salida_{s1} = \\frac{1}{1+e^{-net_{s1}}}$\n",
    "\n",
    "$\\frac{\\partial salida_{s1}}{\\partial net_{s1}} = salida_{s1}(1 - salida_{s1}) = 0.75136507(1 - 0.75136507) = 0.186815602$\n",
    "\n",
    "Finalmente, 驴cu谩nto cambia la entrada neta total de $s1$ con respecto a $w_5$?\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{s1}}{/partial w_{5}} = 1 * salida_{o1} * w_5^{(1 - 1)} + 0 + 0 = salida_{o1} = 0.593269992$\n",
    "\n",
    "Poniendolo todo junto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = \\frac{\\partial E_{total}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial w_{5}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = 0.74136507 * 0.186815602 * 0.593269992 = 0.082167041$\n",
    "\n",
    "Para disminuir el error, luego restamos este valor del peso actual (opcionalmente multiplicado por alguna tasa de aprendizaje, eta, que estableceremos en 0.5):\n",
    "\n",
    "$w_5^{+} = w_5 - \\eta * \\frac{\\partial E_{total}}{\\partial w_{5}} = 0.4 - 0.5 * 0.082167041 = 0.35891648$\n",
    "\n",
    "Podemos repetir este proceso para obtener los nuevos pesos $w_6$, $w_7$ y $w_8$:\n",
    "\n",
    "$w_6^{+} = 0.408666186$\n",
    "\n",
    "$w_7^{+} = 0.511301270$\n",
    "\n",
    "$w_8^{+} = 0.561370121$\n",
    "\n",
    "Realizamos las actualizaciones reales en la red neuronal despu茅s de que tenemos los nuevos pesos que conducen a las neuronas de la capa oculta (es decir, usamos los pesos originales, no los pesos actualizados, cuando continuamos con el algoritmo de retropropagaci贸n a continuaci贸n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capa oculta\n",
    "\n",
    "A continuaci贸n, continuaremos con el paso hacia atr谩s calculando nuevos valores para $w_1$, $w_2$, $w_3$ y $w_4$.\n",
    "\n",
    "Panorama general, esto es lo que debemos averiguar:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{total}}{\\partial salida_{o1}} * \\frac{\\partial salida_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_{1}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{\\partial salida_{h1}}$\n",
    "\n",
    "Visualmente:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_4.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Vamos a usar un proceso similar al que usamos para la capa de salida, pero ligeramente diferente para tener en cuenta el hecho de que la salida de cada neurona de la capa oculta contribuye a la salida (y por lo tanto al error) de varias neuronas de salida. Sabemos que $salida_{o1}$ afecta tanto a $salida_{s1}$ como a $salida_{s2}$, por lo que $\\frac{\\partial E_{total}}{\\partial salida_{o1}}$ debe tener en cuenta su efecto en ambas neuronas de salida :\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{ \\partial salida_{o1}}$\n",
    "\n",
    "Comenzando con $\\frac{\\partial E_{s1}}{\\partial salida_{o1}}$:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial salida_{o1}}$\n",
    "\n",
    "Podemos calcular $\\frac{\\partial E_{s1}}{\\partial net_{s1}}$ usando los valores que calculamos anteriormente:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial net_{s1}} = \\frac{\\partial E_{s1}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} = 0,74136507 * 0,186815602 = 0,138498562$\n",
    "\n",
    "Y $\\frac{\\partial net_{s1}}{\\partial salida_{o1}} es igual a w_5$:\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{s1}}{\\partial salida_{o1}} = w_5 = 0,40$\n",
    "\n",
    "Conect谩ndolos:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial salida_{o1}} = 0,138498562 * 0,40 = 0,055399425$\n",
    "\n",
    "Siguiendo el mismo proceso para $\\frac{\\partial E_{s2}}{\\partial out_{o1}}$, obtenemos:\n",
    "\n",
    "$\\frac{\\partial E_{s2}}{\\partial salida_{o1}} = -0.019049119$\n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{\\partial salida_{o1}} = 0,055399425 + -0,019049119 = 0,036350306$\n",
    "\n",
    "Ahora que tenemos $\\frac{\\partial E_{total}}{\\partial salida_{o1}}$, necesitamos calcular $\\frac{\\partial salida_{o1}}{\\partial net_{o1}}$ y luego $\\frac {\\partial net_{o1}}{\\partial w}$ para cada peso:\n",
    "\n",
    "$salida_{o1} = \\frac{1}{1+e^{-net_{o1}}}$\n",
    "\n",
    "$\\frac{\\partial salida_{o1}}{\\partial net_{o1}} = salida_{o1}(1 - salida_{o1}) = 0,59326999(1 - 0,59326999 ) = 0,241300709$\n",
    "\n",
    "Calculamos la derivada parcial de la entrada neta total a $h_1$ con respecto a $w_1$ igual que hicimos para la neurona de salida:\n",
    "\n",
    "$net_{o1} = w_1 * e_1 + w_3 * e_2 + b_1 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{o1}}{\\partial w_1} = e_1 = 0.05$\n",
    "\n",
    "Poniendolo todo junto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{total}}{\\partial salida_{o1}} * \\frac{\\partial salida_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_{1}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = 0,036350306 * 0,241300709 * 0,05 = 0,000438568$\n",
    "\n",
    "Ahora podemos actualizar $w_1$:\n",
    "\n",
    "$w_1^{+} = w_1 - \\eta * \\frac{\\partial E_{total}}{\\partial w_{1}} = 0,15 - 0,5 * 0,000438568 = 0,149780716$\n",
    "\n",
    "Repitiendo esto para $w_2$, $w_3$ y $w_4$\n",
    "\n",
    "$w_2^{+} = 0.19956143$\n",
    "\n",
    "$w_3^{+} = 0.24975114$\n",
    "\n",
    "$w_4^{+} = 0.29950229$\n",
    "\n",
    "隆Finalmente, hemos actualizado todos nuestros pesos! Cuando alimentamos las entradas 0.05 y 0.1 originalmente, el error en la red fue 0.298371109. Despu茅s de esta primera ronda de propagaci贸n hacia atr谩s, el error total se ha reducido a 0,291027924. Puede que no parezca mucho, pero despu茅s de repetir este proceso 10.000 veces, por ejemplo, el error cae en picado a 0,0000351085. En este punto, cuando alimentamos 0,05 y 0,1, las dos neuronas de salida generan 0,015912196 (vs 0,01 objetivo) y 0,984065734 (vs 0,99 objetivo).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
