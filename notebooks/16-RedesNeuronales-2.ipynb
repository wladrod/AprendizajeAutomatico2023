{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tema 4: Redes Neuronales</h1>\n",
    "    <h1>Redes Neuronales 2</h1>\n",
    "    <br>\n",
    "    <h5>Prof. Wladimir Rodríguez</h5>\n",
    "    <h5>wladimir@ula.ve</h5>\n",
    "    <h5>Departamento de Computación</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de las Redes Neuronales: Propagación Hacia Atrás \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se explicaran los conceptos de la función de costo logístico y el algoritmo de propagación hacia atrás \"Backpropagation\" que se implemantaron en la clase anterior para aprender los pesos de la Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la función de costo logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que se implementó el Perceptron Multicapa para realizar clasificación múltiple, la salida es un vector de $t$ elementos usando la codificación \"one-hot\", por ejemplo la salida de la capa de salida para un ejemplo de la clase 2:\n",
    "\n",
    "$$a^{(salida)}=\\left[\\\n",
    "\\begin{array}{ll}\n",
    "      0.1 \\\\\n",
    "      0.9 \\\\\n",
    "      \\vdots \\\\\n",
    "      0.3 \\\\\n",
    "\\end{array} \n",
    "\\right], \\ y = \\left[\\\n",
    "\\begin{array}{ll}\n",
    "      0 \\\\\n",
    "      1 \\\\\n",
    "      \\vdots \\\\\n",
    "      0 \\\\\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "Por lo que es necesario generalizar la función de costo logístico a todas las $t$ unidades de activación de la red. Por lo que la función de costo es:\n",
    "\n",
    "$$L(\\boldsymbol{W})=\\frac{1}{n}\\sum_{1}^{n}\\sum_{j=1}^{t}(y^{[i]}_j - a_j^{(salida)[i]})^2$$\n",
    "\n",
    "Recordar que nuestro objetivo es minimizar la función de costo $L(\\boldsymbol{W})$; por lo tanto, se necesita calcular la derivada parcial de los parámetros $\\boldsymbol{W}$ con respecto a cada peso para cada capa en la red:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w_{j,l}^{(l)}}L(\\boldsymbol{W})$$\n",
    "\n",
    "A continuación, se presenta el algoritmo de propagación hacia atrás \"backpropagation\", que permite calcular esas derivadas parciales para minimizar la función de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Propagación Hacia Atrás \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esencia, podemos pensar en la propagación hacia atrás \"backpropagation\" como un enfoque computacionalmente muy eficiente para calcular las derivadas parciales de una función de costo compleja en redes neuronales multicapa. Aquí, nuestro objetivo es usar esas derivadas\n",
    "para aprender los coeficientes de peso para parametrizar una red neuronal multicapa.\n",
    "\n",
    "El desafío en la parametrización de redes neuronales es que se esta típicamente tratando con una gran cantidad de coeficientes de peso en un espacio de atributos de muchas dimensiones. En contraste con las funciones de costo de neuronales de una sola capa\n",
    "redes como Adaline o regresión logística, la superficie de error de una función de costo de una red neuronal no es convexa o lisa con respecto a los parámetros. Hay muchos baches en esta superficie de costo multi-dimensional (mínimos locales) que tenemos que superar para encontrar el mínimo de la función de costo.\n",
    "\n",
    "La regla de la cadena es un enfoque para calcular la derivada de una función anidada compleja, como $f(g(x))$, de la siguiente manera:\n",
    "\n",
    "$$\\frac{d}{dx}[f(g(x))]=\\frac{df}{dx}\\cdot\\frac{dg}{dx}$$\n",
    "\n",
    "De manera similar, se puede usar la regla de cadena para una composición de función arbitrariamente larga. Por ejemplo, supongamos que tenemos cinco funciones diferentes, $f(x)$, $g(x)$, $h(x)$, $u(x)$ y $v(x)$, y que $F$ sea la composición de la función: $F(x) = f(g(h(u(v(x)))))$. Aplicando la regla de cadena, podemos calcular la derivada de esta función de la siguiente manera:\n",
    "\n",
    "$$\\frac{dF}{dx}=\\frac{d}{dx}F(x)=\\frac{d}{dx}f(g(h(u(v(x)))))=\\frac{df}{dg}\\cdot\\frac{dg}{dh}\\cdot\\frac{dh}{du}\\cdot\\frac{du}{dv}\\cdot\\frac{dv}{dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando  Redes Neuronales usando Propagación Hacia Atrás \"Backpropagation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, explicaremos la matemática de propagación hacia atrás \"backpropagation\" para entender cómo se pueden aprender los pesos en una red neuronal de manera muy eficiente.\n",
    "\n",
    "Anteriormente vimos como calcular el costo como la diferencia entre la activación de la capa de salida y y la etiqueta de clase objetivo. Ahora veremos como trabaja el algoritmo de propagación hacia atrás para actualizar los pesos en nuestro modelo de Perceptrón Multicapa. \n",
    "\n",
    "Primero necesitamos aplicar la propagación hacia adelante para obtener la activación de la capa de salida, que formulamos de la siguiente manera:\n",
    "\n",
    "$$\\boldsymbol{Z}^{(oculta)}=\\boldsymbol{A}^{(entrada)}\\boldsymbol{W}^{(oculta)T}\\ \\ (entrada\\ a\\ la\\ capa\\ oculta)$$\n",
    "\n",
    "$$\\boldsymbol{A}^{(oculta)}=\\phi(\\boldsymbol{Z}^{(oculta)})\\ \\ (activación\\ de\\ la\\ capa\\ oculta)$$\n",
    "\n",
    "$$\\boldsymbol{Z}^{(salida)}=\\boldsymbol{A}^{(oculta)}\\boldsymbol{W}^{(salida)T}\\ \\ (entrada\\ a\\ la\\ capa\\ de \\ salida)$$\n",
    "\n",
    "$$\\boldsymbol{A}^{(salida)}=\\phi(\\boldsymbol{Z}^{(salida)})\\ \\ (activación\\ de\\ la\\ capa\\ \\ de\\ salida)$$\n",
    "\n",
    "La siguiente figura muestra este proceso:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation.png\" width=\"75%\">\n",
    "\n",
    "En propagación hacia atrás, propagamos el error de derecha a izquierda. Podemos pensar en esto como una aplicación de la regla de la cadena al cálculo de la propagación hacia adelante para calcular el gradiente de la pérdida con respecto a los pesos del modelo (y las unidades de sesgo). Para simplificar, ilustraremos este proceso para la derivada parcial utilizada para actualizar el primer peso en la matriz de peso de la capa de salida. Las rutas del cálculo que propagamos hacia atrás se resaltan mediante las flechas en negrita a continuación:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation_2.png\" width=\"75%\">\n",
    "\n",
    "El gradiente para el peso $ w_{1,1}^{(s)}$ de la capa de salida:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "Si incluimos la entrada $z$ a la neurona:\n",
    "\n",
    "<img src=\"../figuras/neurona_expandida.png\" width=\"25%\">\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "Para calcular esta derivada parcial, comenzaremos con $\\frac{\\partial L}{\\partial a_1^{(s)}}$, que es la derivada parcial de la función de perdida MSE.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_1^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}(y_1 - a_1^{(s)})^2 = 2( a_1^{(s)} - y)$$\n",
    "\n",
    "El próximo término es la derivada de la función de activación logística que se usa en la capa de salida:\n",
    "\n",
    "$$\\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}} = \\frac{\\partial}{\\partial z_1^{(s)}} \\frac{1}{1 + e^{z_1^{(s)}}} = \\cdots = \\left(\\frac{1}{1 + e^{z_1^{(s)}}}\\right) \\left(1 - \\frac{1}{1 + e^{z_1^{(s)}}}\\right)$$\n",
    "\n",
    "$$= a_1^{(s)}(1 - a_1^{(s)})$$\n",
    "\n",
    "Por último, calculamos la derivada de la entrada con respecto al peso:\n",
    "\n",
    "$$\\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial}{\\partial w_{1,1}^{(s)}}a_1^{(o)}w_{1,1}^{(s)} + b_1^{(s)} = a_1^{(o)}$$\n",
    "\n",
    "Poniendo todo junto, obtenemos lo siguiente:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(s)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial w_{1,1}^{(s)}} = 2( a_1^{(s)} - y) \\cdot a_1^{(s)}(1 - a_1^{(s)}) \\cdot a_1^{(o)}$$\n",
    "\n",
    "Luego usamos este valor para actualizar el peso a través de la conocida actualización de descenso de gradiente estocástico con una tasa de aprendizaje de 𝜂:\n",
    "\n",
    "$$w_{1,1}^{(s)} = w_{1,1}^{(s)} - \\eta \\frac{\\partial L}{\\partial w_{1,1}^{(s)}}$$\n",
    "\n",
    "\n",
    "A continuacion se ilustra cómo calcular la derivada parcial de la pérdida con respecto al primer peso de la capa oculta:\n",
    "\n",
    "<img src=\"../figuras/MLP_backpropagation_3.png\" width=\"75%\">\n",
    "\n",
    "Es importante resaltar que dado que el peso $w_{1,1}^{(o)}$ está conectado a ambos nodos de salida, tenemos que usar la regla de la cadena multivariable para sumar las dos rutas resaltadas con flechas en negrita.\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_{1,1}^{(o)}} = \\frac{\\partial L}{\\partial a_1^{(s)}}\\cdot \\frac{\\partial a_1^{(s)}}{\\partial z_1^{(s)}}\\cdot \\frac{\\partial z_1^{(s)}}{\\partial a_1^{(o)}} \\cdot \\frac{\\partial a_1^{(o)}}{\\partial z_1^{(o)}} \\cdot \\frac{\\partial z_1^{(o)}}{\\partial w_{1,1}^{(o)}}\\\\\n",
    "\\qquad \\; + \\frac{\\partial L}{\\partial a_2^{(s)}}\\cdot \\frac{\\partial a_2^{(s)}}{\\partial z_2^{(s)}}\\cdot \\frac{\\partial z_2^{(s)}}{\\partial a_1^{(o)}} \\cdot \\frac{\\partial a_1^{(o)}}{\\partial z_1^{(o)}} \\cdot \\frac{\\partial z_1^{(o)}}{\\partial w_{1,1}^{(o)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo:\n",
    "\n",
    "### Descripción general\n",
    "\n",
    "Para este ejemplo, vamos a utilizar una red neuronal con dos entradas, dos neuronas ocultas, dos neuronas de salida. Además, las neuronas ocultas y de salida incluirán un sesgo.\n",
    "\n",
    "Esta es la estructura básica:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_1.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Para tener algunos números con los que trabajar, aquí están los pesos iniciales, los sesgos y las entradas/salidas de entrenamiento:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_2.png\" width=\"50%\">   \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagación hacia Adelante\n",
    "\n",
    "Así es como calculamos la entrada neta total para $o_1$:\n",
    "\n",
    "$net_{o1} = w_1 * e_1 + w_2 * e_2 + b_1 * 1$\n",
    "\n",
    "$net_{o1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775$\n",
    "\n",
    "Luego aplicamos la función de activación logística para obtener el resultado de $o_1$:\n",
    "\n",
    "$salida_{o1} = \\frac{1}{1+e^{-net_{o1}}} = \\frac{1}{1+e^{-0.3775}} = 0.593269992$\n",
    "\n",
    "Realizando el mismo proceso para $o_2$ obtenemos:\n",
    "\n",
    "$salida_{o2} = 0.596884378$\n",
    "\n",
    "Repetimos este proceso para las neuronas de la capa de salida, usando la salida de las neuronas de la capa oculta como entradas.\n",
    "\n",
    "Aquí está la salida para $s_1$:\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$net_{s1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967$\n",
    "\n",
    "$salida_{s1} = \\frac{1}{1+e^{-net_{o1}}} = \\frac{1}{1+e^{-1.105905967}} = 0.75136507$\n",
    "\n",
    "Realizando el mismo proceso para $s_2$ obtenemos:\n",
    "\n",
    "$salida_{s2} = 0.772928465$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular el Error Total\n",
    "\n",
    "Ahora podemos calcular el error de cada neurona de salida usando la función de error al cuadrado y sumarlos para obtener el error total:\n",
    "\n",
    "$E_{total} = \\sum \\frac{1}{2}(objetivo - salida)^{2}$\n",
    "\n",
    "Por ejemplo, la salida objetivo para $s_1$ es $0.01$ pero la salida de la red neuronal es $0.75136507$, por lo que su error es:\n",
    "\n",
    "$E_{s1} = \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2} = \\frac{1}{2}(0.01 - 0.75136507)^{2} = 0.274811083$\n",
    "\n",
    "Repitiendo este proceso para $s_2$ (recordando que el objetivo es 0.99) obtenemos:\n",
    "\n",
    "$E_{s2} = 0.023560026$\n",
    "\n",
    "El error total de la red neuronal es la suma de estos errores:\n",
    "\n",
    "$E_{total} = E_{s1} + E_{s2} = 0.274811083 + 0.023560026 = 0.298371109$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Propagación hacias Atrás\n",
    "\n",
    "Nuestro objetivo con la propagación hacia atrás es actualizar cada uno de los pesos en la red para que hagan que la salida real esté más cerca de la salida objetivo, minimizando así el error para cada neurona de salida y la red como un todo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capa de salida\n",
    "\n",
    "Considere $w_5$. Queremos saber cuánto afecta un cambio en $w_5$ al error total, también conocido como $\\frac{\\partial E_{total}}{\\partial w_{5}}$\n",
    "\n",
    "Aplicando la regla de la cadena sabemos que:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = \\frac{\\partial E_{total}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial w_{5}}$\n",
    "\n",
    "Visualmente, esto es lo que estamos haciendo:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_3.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Tenemos que averiguar cada pieza en esta ecuación.\n",
    "\n",
    "Primero, ¿cuánto cambia el error total con respecto a la salida?\n",
    "\n",
    "$E_{total} = \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2} + \\frac{1}{2}(objetivo_{s2} - salida_{s2})^{2}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{s1}} = 2 * \\frac{1}{2}(objetivo_{s1} - salida_{s1})^{2 - 1} * -1 + 0$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{s1}} = -(objetivo_{s1} - salida_{s1}) = -(0.01 - 0.75136507) = 0.74136507$\n",
    "\n",
    "Luego, ¿cuánto cambia la salida de $s_1$ con respecto a su entrada neta total?\n",
    "\n",
    "La derivada parcial de la función logística es la salida multiplicada por 1 menos la salida:\n",
    "\n",
    "$salida_{s1} = \\frac{1}{1+e^{-net_{s1}}}$\n",
    "\n",
    "$\\frac{\\partial salida_{s1}}{\\partial net_{s1}} = salida_{s1}(1 - salida_{s1}) = 0.75136507(1 - 0.75136507) = 0.186815602$\n",
    "\n",
    "Finalmente, ¿cuánto cambia la entrada neta total de $s1$ con respecto a $w_5$?\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{s1}}{/partial w_{5}} = 1 * salida_{o1} * w_5^{(1 - 1)} + 0 + 0 = salida_{o1} = 0.593269992$\n",
    "\n",
    "Poniendolo todo junto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = \\frac{\\partial E_{total}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial w_{5}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{5}} = 0.74136507 * 0.186815602 * 0.593269992 = 0.082167041$\n",
    "\n",
    "Para disminuir el error, luego restamos este valor del peso actual (opcionalmente multiplicado por alguna tasa de aprendizaje, eta, que estableceremos en 0.5):\n",
    "\n",
    "$w_5^{+} = w_5 - \\eta * \\frac{\\partial E_{total}}{\\partial w_{5}} = 0.4 - 0.5 * 0.082167041 = 0.35891648$\n",
    "\n",
    "Podemos repetir este proceso para obtener los nuevos pesos $w_6$, $w_7$ y $w_8$:\n",
    "\n",
    "$w_6^{+} = 0.408666186$\n",
    "\n",
    "$w_7^{+} = 0.511301270$\n",
    "\n",
    "$w_8^{+} = 0.561370121$\n",
    "\n",
    "Realizamos las actualizaciones reales en la red neuronal después de que tenemos los nuevos pesos que conducen a las neuronas de la capa oculta (es decir, usamos los pesos originales, no los pesos actualizados, cuando continuamos con el algoritmo de retropropagación a continuación)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capa oculta\n",
    "\n",
    "A continuación, continuaremos con el paso hacia atrás calculando nuevos valores para $w_1$, $w_2$, $w_3$ y $w_4$.\n",
    "\n",
    "Panorama general, esto es lo que debemos averiguar:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{total}}{\\partial salida_{o1}} * \\frac{\\partial salida_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_{1}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{\\partial salida_{h1}}$\n",
    "\n",
    "Visualmente:\n",
    "\n",
    "<center>\n",
    " <img src=\"../figuras/net_4.png\" width=\"50%\">   \n",
    "</center>\n",
    "\n",
    "Vamos a usar un proceso similar al que usamos para la capa de salida, pero ligeramente diferente para tener en cuenta el hecho de que la salida de cada neurona de la capa oculta contribuye a la salida (y por lo tanto al error) de varias neuronas de salida. Sabemos que $salida_{o1}$ afecta tanto a $salida_{s1}$ como a $salida_{s2}$, por lo que $\\frac{\\partial E_{total}}{\\partial salida_{o1}}$ debe tener en cuenta su efecto en ambas neuronas de salida :\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{ \\partial salida_{o1}}$\n",
    "\n",
    "Comenzando con $\\frac{\\partial E_{s1}}{\\partial salida_{o1}}$:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial salida_{o1}}$\n",
    "\n",
    "Podemos calcular $\\frac{\\partial E_{s1}}{\\partial net_{s1}}$ usando los valores que calculamos anteriormente:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial net_{s1}} = \\frac{\\partial E_{s1}}{\\partial salida_{s1}} * \\frac{\\partial salida_{s1}}{\\partial net_{s1}} = 0,74136507 * 0,186815602 = 0,138498562$\n",
    "\n",
    "Y $\\frac{\\partial net_{s1}}{\\partial salida_{o1}} es igual a w_5$:\n",
    "\n",
    "$net_{s1} = w_5 * salida_{o1} + w_6 * salida_{o2} + b_2 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{s1}}{\\partial salida_{o1}} = w_5 = 0,40$\n",
    "\n",
    "Conectándolos:\n",
    "\n",
    "$\\frac{\\partial E_{s1}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial net_{s1}} * \\frac{\\partial net_{s1}}{\\partial salida_{o1}} = 0,138498562 * 0,40 = 0,055399425$\n",
    "\n",
    "Siguiendo el mismo proceso para $\\frac{\\partial E_{s2}}{\\partial out_{o1}}$, obtenemos:\n",
    "\n",
    "$\\frac{\\partial E_{s2}}{\\partial salida_{o1}} = -0.019049119$\n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial salida_{o1}} = \\frac{\\partial E_{s1}}{\\partial salida_{o1}} + \\frac{\\partial E_{s2}}{\\partial salida_{o1}} = 0,055399425 + -0,019049119 = 0,036350306$\n",
    "\n",
    "Ahora que tenemos $\\frac{\\partial E_{total}}{\\partial salida_{o1}}$, necesitamos calcular $\\frac{\\partial salida_{o1}}{\\partial net_{o1}}$ y luego $\\frac {\\partial net_{o1}}{\\partial w}$ para cada peso:\n",
    "\n",
    "$salida_{o1} = \\frac{1}{1+e^{-net_{o1}}}$\n",
    "\n",
    "$\\frac{\\partial salida_{o1}}{\\partial net_{o1}} = salida_{o1}(1 - salida_{o1}) = 0,59326999(1 - 0,59326999 ) = 0,241300709$\n",
    "\n",
    "Calculamos la derivada parcial de la entrada neta total a $h_1$ con respecto a $w_1$ igual que hicimos para la neurona de salida:\n",
    "\n",
    "$net_{o1} = w_1 * e_1 + w_3 * e_2 + b_1 * 1$\n",
    "\n",
    "$\\frac{\\partial net_{o1}}{\\partial w_1} = e_1 = 0.05$\n",
    "\n",
    "Poniendolo todo junto:\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = \\frac{\\partial E_{total}}{\\partial salida_{o1}} * \\frac{\\partial salida_{o1}}{\\partial net_{o1}} * \\frac{\\partial net_{o1}}{\\partial w_{1}}$\n",
    "\n",
    "$\\frac{\\partial E_{total}}{\\partial w_{1}} = 0,036350306 * 0,241300709 * 0,05 = 0,000438568$\n",
    "\n",
    "Ahora podemos actualizar $w_1$:\n",
    "\n",
    "$w_1^{+} = w_1 - \\eta * \\frac{\\partial E_{total}}{\\partial w_{1}} = 0,15 - 0,5 * 0,000438568 = 0,149780716$\n",
    "\n",
    "Repitiendo esto para $w_2$, $w_3$ y $w_4$\n",
    "\n",
    "$w_2^{+} = 0.19956143$\n",
    "\n",
    "$w_3^{+} = 0.24975114$\n",
    "\n",
    "$w_4^{+} = 0.29950229$\n",
    "\n",
    "¡Finalmente, hemos actualizado todos nuestros pesos! Cuando alimentamos las entradas 0.05 y 0.1 originalmente, el error en la red fue 0.298371109. Después de esta primera ronda de propagación hacia atrás, el error total se ha reducido a 0,291027924. Puede que no parezca mucho, pero después de repetir este proceso 10.000 veces, por ejemplo, el error cae en picado a 0,0000351085. En este punto, cuando alimentamos 0,05 y 0,1, las dos neuronas de salida generan 0,015912196 (vs 0,01 objetivo) y 0,984065734 (vs 0,99 objetivo).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
