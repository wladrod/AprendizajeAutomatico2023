{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tema 2: Aprendizaje Supervisado</h1>\n",
    "    <br/>\n",
    "    <h1>Clasificador Bayesiano Ingenuo (Naive Bayes)</h1>\n",
    "    <br>\n",
    "    <h5>Prof. Wladimir Rodriguez</h5>\n",
    "    <h5>wladimir@ula.ve</h5>\n",
    "    <h5>Departamento de Computación</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "- Es un tipo de aprendizaje supervisado: Se conoce la clase verdadera de cada uno de los ejemplos que se utilizan para construir el clasificador\n",
    "- El problema de clasificación consiste en predecir una determinada clase (categórica) para un objeto\n",
    "- **La tarea de clasificación**: Dados un conjunto de ejemplos ya clasificados, construir un modelo o clasificador que permita clasificar nuevos casos\n",
    "- El problema fundamental de la clasificación está directamente relacionado con la separabilidad de las clases.\n",
    "\n",
    "### Clases linealmente separables\n",
    "\n",
    "<img src=\"../figuras/ClasificacionLineal.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "### Clases no linealmente separables\n",
    "\n",
    "<img src=\"../figuras/NoLinearSeparable.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Clasificación\n",
    "\n",
    "Estudiaremos algunos de los algoritmos de clasificación mas utilizados:\n",
    "\n",
    "+ Clasificador Bayesiano Ingenuo (Naive Bayes)\n",
    "+ Perceptrón Simple\n",
    "+ Regresión Logística\n",
    "+ Vecino más cercano\n",
    "+ Árboles de decisión\n",
    "+ Support vector machines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores Bayesianos Ingenuos (*Naive Bayes Classifiers*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes es un algoritmo de aprendizaje automático para problemas de clasificación. Esta basado en el teorema de probabilidad de Bayes. Se utiliza principalmente para la clasificación de texto la cual implica conjuntos de datos de entrenamiento con una alta dimensionalidad. Algunos ejemplos son filtración de correos basura, análisis de sentimiento y clasificación de artículos de noticias.\n",
    "\n",
    "No sólo es conocido por su simplicidad, sino también por su eficacia. Es rápido construir modelos y hacer predicciones con el algoritmo Naive Bayes. Naive Bayes es el primer algoritmo que debe ser considerado para resolver problemas de clasificación de texto. Por lo tanto, es importante aprender este algoritmo a fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es el algoritmo Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes es un algoritmo que aprende la probabilidad de que un objeto con ciertos atributos pertenesca a un grupo o una clase en particular. En resumen, es un clasificador probabilístico. ¿Por qué se llama así?\n",
    "\n",
    "El algoritmo Naive Bayes se llama \"ingenuo\" porque hace la suposición de que la ocurrencia de un atributo en particular es independiente de la ocurrencia de los otros atributos.\n",
    "\n",
    "Por ejemplo, si tratamos de identificar una fruta basada en su color, forma y sabor, entonces una fruta de color naranja, esférica y ácida sería muy probablemente una naranja. Incluso si estos atributos dependen unos de otros o de la presencia de las otros atributos, todas estos atributos contribuyen individualmente a la probabilidad de que esta fruta es una naranja y es por eso que se conoce como \"ingenuo\".\n",
    "\n",
    "En cuanto a la parte de \"Bayes\", se refiere al estadístico y filósofo, Thomas Bayes y el teorema que lleva su nombre, el teorema de Bayes, que es la base para el Algoritmo Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Matemáticas del Algoritmo Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base del algoritmo Naive Bayes es el Teorema de Bayes o también conocido como la Regla de Bayes o la Ley de Bayes. Nos da un método para calcular la probabilidad condicional, es decir, la probabilidad de un evento basado en conocimientos previos disponibles sobre los eventos. Más formalmente, el teorema de Bayes se expresa como la siguiente ecuación:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)\\times P(A)}{P(B)}$$\n",
    "\n",
    "Entendamos la declaración primero y luego examinaremos la prueba de la declaración. Los componentes de la declaración anterior son:\n",
    "\n",
    "- $P (A|B)$: Probabilidad (probabilidad condicional) de ocurrencia del evento A dado el evento B es verdadero\n",
    "- $P (A)$ y $P (B)$: Probabilidades de la ocurrencia del evento A y B respectivamente\n",
    "- $P (B | A)$: Probabilidad de la ocurrencia del evento B dado que el evento A es verdadero\n",
    "\n",
    "La terminología del método bayesiano de probabilidad (más comúnmente utilizada) es la siguiente:\n",
    "\n",
    "$$P(h|D) = \\frac{P(D|h)\\times P(h)}{P(D)}$$\n",
    "\n",
    "- $h$ se le denomina la hipótesis y a $D$ se le denomina la observación.\n",
    "- $P(h)$  Probabilidad de que la hipótesis `h` sea cierta o probabilidad a priori de la hipótesis `h`.\n",
    "- $P(D)$  Probabilidad de que recibamos la observación `D` o probabilidad a priori de la observación `D`.\n",
    "- $P(D|h)$  Probabilidad de observar el dato `D`, cuando se cumple la hipótesis `h` o probabilidad a posteriori de la observación `D`.\n",
    "- $P(h|D)$  Probabilidad de que se cumpla la hipótesis `h`, dado que se ha obtenido el dato `D`, o probabilidad a posteriori de la hipótesis `h`.\n",
    "\n",
    "\n",
    "Por lo que podemos reescribir el Teorema de Bayes como:\n",
    "\n",
    "$$Probabilidad\\ posterior\\ hipótesis = \\frac{(Verosimilitud)\\times (Probabilidad\\ previa\\ hipótesis)}{Probabilidad\\ previa\\ observación}$$\n",
    "\n",
    "En general estamos interesados en calcular el **decisor máximo a posteriori**:\n",
    "\n",
    "$$h_{MAP}=argmax_h\\ P(h|D) = argmax_h\\ \\frac{P(D|h)\\times P(h)}{P(D)}$$\n",
    "\n",
    "Dado que $P(D)$ es constante para todas las hipótesis, lo podemos eliminar\n",
    "\n",
    "$$h_{MAP}=argmax_h\\ P(h|D) = argmax_h\\ {P(D|h)\\times P(h)}$$\n",
    "\n",
    "En el caso de que todas las hipótesis sea equiprobables a priori. Se puede calcular el **decisor de máxima verosimilitud**:\n",
    "\n",
    "$$h_{ML}=argmax_h\\ P(D|h)$$\n",
    "\n",
    "**Tomemos un ejemplo para entender mejor el teorema de Bayes.**\n",
    "\n",
    "Supongamos que usted tiene que sacar una sola carta de una baraja estándar de 52 cartas. Ahora la probabilidad de que la carta sea una Reina es $P(Reina) = \\frac{4}{52} = \\frac{1}{13}$. Si se le da evidencia de que la carta que ha escogido es una carta con una persona, la probabilidad posterior $P(Reina | Persona)$ se puede calcular usando el teorema de Bayes como sigue:\n",
    "\n",
    "$$P(Reina|Persona) = \\frac{P(Persona|Reina)\\times P(Reina)}{P(Persona)}$$\n",
    "\n",
    "Ahora $P (Persona | Reina) = 1$ porque dada que la carta es una reina, es definitivamente una carta de una persona. Ya hemos calculado $P(Reina)$. El único valor que queda para calcular es $P(Persona)$, que es igual a $\\frac {3} {13}$ ya que hay tres cartas de personas para cada palo en una baraja. Por lo tanto,\n",
    "\n",
    "$$P(Reina|Persona) = 1 \\times \\frac{1}{13}\\times \\frac{13}{3}=\\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación usando Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un problema de clasificación de aprendizaje automático, hay varios atributos y clases, digamos, $C_1, C_2, \\ldots, C_k$. El objetivo principal del algoritmo Naive Bayes es calcular la probabilidad condicional de que un objeto con un vector de atributos $x_1, x_2, \\ldots, x_n$ pertenezca a una clase particular $C_i$,\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = \\frac{P(x_1, x_2, \\ldots, x_n|C_i)\\times P(C_i)}{P(x_1, x_2, \\ldots, x_n)}\\ para\\ 1 ≤ i ≤ k$$\n",
    "\n",
    "Dada la suposición de que los atributos son independientes podemos decir que:\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = (\\prod_{j=1}^{j=n}P(x_j|C_i))\\times \\frac{P(C_i)}{P(x_1, x_2, \\ldots, x_n)}\\ para\\ 1 ≤ i ≤ k$$\n",
    "\n",
    "La expresion $P(x_1, x_2, \\ldots, x_n)$ es constante para todas las clases, podemos entonces decir que\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = (\\prod_{j=1}^{j=n}P(x_j|C_i))\\times P(C_i)\\ para\\ 1 ≤ i ≤ k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona el Algoritmo Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos aprendido cuál es el algoritmo Naive Bayes, cómo se relaciona el Teorema de Bayes con él y cuál es la expresión del Teorema de Bayes para este algoritmo. Tomemos un ejemplo simple la siguente tabla con ejemplos si debemos jugar al tenis bajo ciertas circunstancias. Éstas podrían ser el clima, la temperatura, la humedad y la fuerza del viento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos y convetir los valores categoricos en valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clima</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Humedad</th>\n",
       "      <th>Viento</th>\n",
       "      <th>Jugar_Tenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clima Temperatura Humedad  Viento Jugar_Tenis\n",
       "0   Soleado        Alta    Alta   Débil          No\n",
       "1   Soleado        Alta    Alta  Fuerte          No\n",
       "2   Nublado        Alta    Alta   Débil          Si\n",
       "3    Lluvia       Media    Alta   Débil          Si\n",
       "4    Lluvia        Baja  Normal   Débil          Si\n",
       "5    Lluvia        Baja  Normal  Fuerte          No\n",
       "6   Nublado        Baja  Normal  Fuerte          Si\n",
       "7   Soleado       Media    Alta   Débil          No\n",
       "8   Soleado        Baja  Normal   Débil          Si\n",
       "9    Lluvia       Media  Normal   Débil          Si\n",
       "10  Soleado       Media  Normal  Fuerte          Si\n",
       "11  Nublado       Media    Alta  Fuerte          Si\n",
       "12  Nublado        Alta  Normal   Débil          Si\n",
       "13   Lluvia       Media    Alta  Fuerte          No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv('../datos/temperatura.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir los valores no numéricos a valores numéricos\n",
    "\n",
    "Los algoritmos de aprendizaje automático solo pueden funcionar con valores numéricos, por lo que se hace necesario convertir aquellos valores no numéricos a numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clima ['Lluvia' 'Nublado' 'Soleado']\n",
      "Temperatura ['Alta' 'Baja' 'Media']\n",
      "Humedad ['Alta' 'Normal']\n",
      "Viento ['Débil' 'Fuerte']\n",
      "Jugar_Tenis ['No' 'Si']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clima</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Humedad</th>\n",
       "      <th>Viento</th>\n",
       "      <th>Jugar_Tenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Clima  Temperatura  Humedad  Viento  Jugar_Tenis\n",
       "0       2            0        0       0            0\n",
       "1       2            0        0       1            0\n",
       "2       1            0        0       0            1\n",
       "3       0            2        0       0            1\n",
       "4       0            1        1       0            1\n",
       "5       0            1        1       1            0\n",
       "6       1            1        1       1            1\n",
       "7       2            2        0       0            0\n",
       "8       2            1        1       0            1\n",
       "9       0            2        1       0            1\n",
       "10      2            2        1       1            1\n",
       "11      1            2        0       1            1\n",
       "12      1            0        1       0            1\n",
       "13      0            2        0       1            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for colname in datos.columns:\n",
    "    le.fit(datos[colname])\n",
    "    print(colname, le.classes_)\n",
    "    datos[colname] = le.transform(datos[colname])\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de la Clase Si:  0.6428571428571429\n",
      "Probabilidad de la Clase No:  0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de Ejemplos de la Clase Si\n",
    "Clase_Si = datos['Jugar_Tenis'][datos['Jugar_Tenis'] == 1].count()\n",
    "\n",
    "# Cantidad de Ejemplos de la Clase No\n",
    "Clase_No = datos['Jugar_Tenis'][datos['Jugar_Tenis'] == 0].count()\n",
    "\n",
    "# Total de ejemplos\n",
    "total = datos['Jugar_Tenis'].count()\n",
    "\n",
    "# Probabilidad de la Clase Si\n",
    "P_Si = Clase_Si/total\n",
    "\n",
    "# Probabilidad de la Clase No\n",
    "P_No = Clase_No/total\n",
    "\n",
    "print(\"Probabilidad de la Clase Si: \", P_Si)\n",
    "print(\"Probabilidad de la Clase No: \", P_No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jugar_Si</th>\n",
       "      <th>Jugar_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lluvia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nublado</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soleado</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltaT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BajaT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MediaT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltaH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Devil</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuerte</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Jugar_Si  Jugar_No\n",
       "Lluvia        0.0       0.0\n",
       "Nublado       0.0       0.0\n",
       "Soleado       0.0       0.0\n",
       "AltaT         0.0       0.0\n",
       "BajaT         0.0       0.0\n",
       "MediaT        0.0       0.0\n",
       "AltaH         0.0       0.0\n",
       "NormalH       0.0       0.0\n",
       "Devil         0.0       0.0\n",
       "Fuerte        0.0       0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice = ['Lluvia', 'Nublado', 'Soleado', 'AltaT', 'BajaT',\n",
    "         'MediaT', 'AltaH', 'NormalH', 'Devil', 'Fuerte']\n",
    "\n",
    "columnas = ['Jugar_Si', 'Jugar_No']\n",
    "\n",
    "mapa_columnas = {'Lluvia':'Clima', 'Nublado':'Clima', 'Soleado':'Clima',\n",
    "                 'AltaT':'Temperatura', 'MediaT':'Temperatura','BajaT':'Temperatura',\n",
    "                 'AltaH':'Humedad', 'NormalH':'Humedad',\n",
    "                 'Devil':'Viento', 'Fuerte':'Viento'}\n",
    "\n",
    "mapa_valores = {'Lluvia':0, 'Nublado':1, 'Soleado':2,\n",
    "                 'AltaT':0, 'BajaT':2,'MediaT':1,\n",
    "                 'AltaH':0, 'NormalH':1,\n",
    "                 'Devil':0, 'Fuerte':1}\n",
    "\n",
    "cond_prob_df = pd.DataFrame( np.zeros([10,2]), columns = columnas, index =indice)\n",
    "cond_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jugar_Si</th>\n",
       "      <th>Jugar_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lluvia</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nublado</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soleado</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltaT</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BajaT</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MediaT</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltaH</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalH</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Devil</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuerte</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Jugar_Si  Jugar_No\n",
       "Lluvia   0.333333       0.4\n",
       "Nublado  0.444444       0.0\n",
       "Soleado  0.222222       0.6\n",
       "AltaT    0.222222       0.4\n",
       "BajaT    0.444444       0.4\n",
       "MediaT   0.333333       0.2\n",
       "AltaH    0.333333       0.8\n",
       "NormalH  0.666667       0.2\n",
       "Devil    0.666667       0.4\n",
       "Fuerte   0.333333       0.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, attr in enumerate(indice):\n",
    "    cond_prob_df.loc[attr, 'Jugar_Si'] = ((datos[mapa_columnas[attr]] == mapa_valores[attr]) & (datos['Jugar_Tenis'] == 1)).sum()/float(total)/float(P_Si)\n",
    "    cond_prob_df.loc[attr, 'Jugar_No'] = ((datos[mapa_columnas[attr]] == mapa_valores[attr]) & (datos['Jugar_Tenis'] == 0)).sum()/float(total)/float(P_No)\n",
    "cond_prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular las Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clima</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Humedad</th>\n",
       "      <th>Viento</th>\n",
       "      <th>Jugar_Tenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Baja</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>Media</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clima Temperatura Humedad  Viento Jugar_Tenis\n",
       "0   Soleado        Alta    Alta   Débil          No\n",
       "1   Soleado        Alta    Alta  Fuerte          No\n",
       "2   Nublado        Alta    Alta   Débil          Si\n",
       "3    Lluvia       Media    Alta   Débil          Si\n",
       "4    Lluvia        Baja  Normal   Débil          Si\n",
       "5    Lluvia        Baja  Normal  Fuerte          No\n",
       "6   Nublado        Baja  Normal  Fuerte          Si\n",
       "7   Soleado       Media    Alta   Débil          No\n",
       "8   Soleado        Baja  Normal   Débil          Si\n",
       "9    Lluvia       Media  Normal   Débil          Si\n",
       "10  Soleado       Media  Normal  Fuerte          Si\n",
       "11  Nublado       Media    Alta  Fuerte          Si\n",
       "12  Nublado        Alta  Normal   Débil          Si\n",
       "13   Lluvia       Media    Alta  Fuerte          No"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos1 = pd.read_csv('../datos/temperatura.csv')\n",
    "datos1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad de la Clase Si = 9/14\n",
    "\n",
    "Probabilidad de la Clase No = 5/14\n",
    "\n",
    "Para el atributo Clima:\n",
    "\n",
    "| Clima  | Jugar = Si | Jugar = No |\n",
    ":-----:|:--------: | :---------:\n",
    "|  Soleado  | 2/9 | 3/5 |\n",
    "| Nublado  | 4/9 | 0/5 |\n",
    "| Lluvia   | 3/9 | 2/5 |\n",
    "  \n",
    "\n",
    "Para el atributo Temperatura:\n",
    "\n",
    "Temperatura  | Jugar = Si | Jugar = No |\n",
    ":-----:|:--------: | :---------:\n",
    "  Alta  | 2/9 | 2/5\n",
    "  Media  | 4/9 | 2/5\n",
    "  Baja   | 3/9 | 1/5\n",
    "  \n",
    "  \n",
    "Para el atributo Humedad:\n",
    "\n",
    "Humedad  | Jugar = Si | Jugar = No |\n",
    "  :-----:|:--------: | :---------:\n",
    "  Alta  | 3/9 | 4/5\n",
    "  Normal  | 6/9 | 1/5\n",
    "  \n",
    "Para el atributo Viento:\n",
    "\n",
    "Viento  | Jugar = Si | Jugar = No |\n",
    "  :-----:|:--------: | :---------:\n",
    "  Fuerte  | 3/9 | 3/5\n",
    "  Débil  | 6/9 | 2/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad de Jugar si los atributos son: \n",
    "### Clima = Soleado, Temperatura = Baja, Humedad = Alta, Viento = Fuerte\n",
    "\n",
    "\n",
    "Probabilidad de Si = $\\frac{2}{9}\\times \\frac{3}{9}\\times \\frac{3}{9}\\times \\frac{3}{9}\\times \\frac{9}{14}$ = 0,0053\n",
    "\n",
    "Probabilidad de No = $\\frac{3}{5}\\times \\frac{1}{5}\\times \\frac{4}{5}\\times \\frac{3}{5}\\times \\frac{5}{14}$ = 0,0206\n",
    "\n",
    "La predicción es No\n",
    "\n",
    "Normalizando:\n",
    "\n",
    "Probabilidad de Si = $\\frac{0.0053}{0.0053+0.0206}$ = 0.205\n",
    "\n",
    "Probabilidad de No = $\\frac{0.0206}{0.0053+0.0206}$ = 0.795"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes con atributos continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clima</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Humedad</th>\n",
       "      <th>Viento</th>\n",
       "      <th>Jugar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>29.4</td>\n",
       "      <td>85</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>26.7</td>\n",
       "      <td>90</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>28.3</td>\n",
       "      <td>86</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>21.1</td>\n",
       "      <td>96</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>18.3</td>\n",
       "      <td>70</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>17.8</td>\n",
       "      <td>65</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>22.2</td>\n",
       "      <td>95</td>\n",
       "      <td>Débil</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>20.6</td>\n",
       "      <td>70</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>23.9</td>\n",
       "      <td>80</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soleado</td>\n",
       "      <td>23.9</td>\n",
       "      <td>70</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>22.2</td>\n",
       "      <td>90</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>27.2</td>\n",
       "      <td>75</td>\n",
       "      <td>Débil</td>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lluvia</td>\n",
       "      <td>21.7</td>\n",
       "      <td>91</td>\n",
       "      <td>Fuerte</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clima  Temperatura  Humedad  Viento Jugar\n",
       "0   Soleado         29.4       85   Débil    No\n",
       "1   Soleado         26.7       90  Fuerte    No\n",
       "2   Nublado         28.3       86   Débil    Si\n",
       "3    Lluvia         21.1       96   Débil    Si\n",
       "4    Lluvia         20.0       80   Débil    Si\n",
       "5    Lluvia         18.3       70  Fuerte    No\n",
       "6   Nublado         17.8       65  Fuerte    Si\n",
       "7   Soleado         22.2       95   Débil    No\n",
       "8   Soleado         20.6       70   Débil    Si\n",
       "9    Lluvia         23.9       80   Débil    Si\n",
       "10  Soleado         23.9       70  Fuerte    Si\n",
       "11  Nublado         22.2       90  Fuerte    Si\n",
       "12  Nublado         27.2       75   Débil    Si\n",
       "13   Lluvia         21.7       91  Fuerte    No"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_2 = pd.read_csv('../datos/temperatura_num.csv')\n",
    "datos_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular media y desviación estandar para cada calse de los atributos continuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo Temperatura:\n",
    "\n",
    "Temperatura, Jugar=Si | Temperatura, Jugar=No |\n",
    "  ------------- | -------------\n",
    "  28.3 | 28.4\n",
    "  21.1 | 26.7\n",
    "  20.0 | 18.3\n",
    "  17.8 | 22.2\n",
    "  20.6 | 21.7\n",
    "  23.9 |\n",
    "  23.9 |\n",
    "  22.2 |\n",
    "  27.2 |\n",
    "media: 22.8 | 23.7\n",
    "desviación estandar: 3.4 | 4.4\n",
    "\n",
    "Para el atributo Humedad:\n",
    "\n",
    "Humedad, Jugar=Si | Humedad, Jugar=No |\n",
    "  ------------- | -------------\n",
    "  86 | 85\n",
    "  96 | 90\n",
    "  80 | 70\n",
    "  65 | 95\n",
    "  70 | 91\n",
    "  80 |\n",
    "  70 |\n",
    "  90 |\n",
    "  75 |\n",
    "media: 79.1 | 86.2\n",
    "desviación estandar: 10.2 | 9.7\n",
    "\n",
    "\n",
    "Asumiendo que la distribución es normal se utiliza la siguiente formula para calcular la probabilidad de la evidencia dada la clase\n",
    "\n",
    "$$\n",
    "P(x_j|C_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{ij}}{e}^{-\\frac{(x_j-\\mu_{ij})^2}{2\\sigma_{ij}^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jugar\n",
       "No    23.660000\n",
       "Si    22.777778\n",
       "Name: Temperatura, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de la media de la temperatura usando pandas\n",
    "datos_2.groupby('Jugar')['Temperatura'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jugar\n",
       "No    4.384404\n",
       "Si    3.408731\n",
       "Name: Temperatura, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de la desviación estándar de la temperatura usando pandas\n",
    "datos_2.groupby('Jugar')['Temperatura'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jugar\n",
       "No    86.200000\n",
       "Si    79.111111\n",
       "Name: Humedad, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de la media de la humedad usando pandas\n",
    "datos_2.groupby('Jugar')['Humedad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jugar\n",
       "No     9.731393\n",
       "Si    10.215729\n",
       "Name: Humedad, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo de la desviación estándar de la humedad usando pandas\n",
    "datos_2.groupby('Jugar')['Humedad'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad de Jugar si los atributos son: \n",
    "### Clima = Soleado, Temperatura = 24, Humedad = 74, Viento = Fuerte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad de Temperatura = 24 y Jugar = Si\n",
    "\n",
    "$$\n",
    "P(Temperatura=24|Jugar = Si) = {\\frac{1}{\\sqrt{2\\pi}(3.4)}{e}^{-\\frac{(24-22.8)^2}{2(3.4)^2}}}=0.117\n",
    "$$\n",
    "\n",
    "Probabilidad de Temperatura = 24 y Jugar = No\n",
    "\n",
    "$$\n",
    "P(Temperatura=24|Jugar = No) = {\\frac{1}{\\sqrt{2\\pi}(4.4)}{e}^{-\\frac{(24-23.7)^2}{2(4.4)^2}}}=0.09\n",
    "$$\n",
    "\n",
    "Probabilidad de Humedad = 74 y Jugar = Si\n",
    "\n",
    "$$\n",
    "P(Humedad=74|Jugar = Si) = {\\frac{1}{\\sqrt{2\\pi}(10.2)}{e}^{-\\frac{(74-79.1)^2}{2(10.2)^2}}}=0.035\n",
    "$$\n",
    "\n",
    "Probabilidad de Humedad = 74 y Jugar = No\n",
    "\n",
    "$$\n",
    "P(Humedad=74|Jugar = No) = {\\frac{1}{\\sqrt{2\\pi}(9.7)}{e}^{-\\frac{(74-86.2)^2}{2(9.7)^2}}}=0.019\n",
    "$$\n",
    "\n",
    "\n",
    "Probabilidad de Si = $\\frac{2}{9}\\times 0.117\\times 0.035\\times \\frac{3}{9}\\times \\frac{9}{14}$ = 0,000195\n",
    "\n",
    "Probabilidad de No = $\\frac{3}{5}\\times 0.09\\times 0.019\\times \\frac{3}{5}\\times \\frac{5}{14}$ = 0,00022\n",
    "\n",
    "La predicción es No\n",
    "\n",
    "Normalizando:\n",
    "\n",
    "Probabilidad de Si = $\\frac{0,000195}{0,000195+0,00022}$ = 0.470\n",
    "\n",
    "Probabilidad de No = $\\frac{0.00022}{0,000195+0,00022}$ = 0.530"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventajas y desventajas de Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventajas:\n",
    "\n",
    "- Extremadamente rápido para entrenar / aplicar (solo contar cosas)\n",
    "- Bueno en la clasificación de documentos y el filtrado de correo basura.\n",
    "- Proporciona una predicción probabilística directa.\n",
    "- Naive Bayes tiene un costo de cálculo muy bajo.\n",
    "- Se puede utilizar con problemas de predicción de múltiples clases.\n",
    "- Es simple y fácil de implementar.\n",
    "- No requiere tantos datos de entrenamiento.\n",
    "- Maneja tanto datos continuos como discretos.\n",
    "- Es altamente escalable con la cantidad de predictores y puntos de datos.\n",
    "- Es rápido y se puede utilizar para hacer predicciones en tiempo real.\n",
    "- No es sensible a atributos irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desventajas:\n",
    "\n",
    "- Naive Bayes asume que todos los predictores (o características) son independientes y rara vez suceden en la vida real. Esto limita la aplicabilidad de este algoritmo en casos de uso del mundo real.\n",
    "- Cuando el conjunto de atributos es grande (y escaso, como los atributos de palabras en la clasificación de texto) Bayes ingenuo podría \"contar dos veces\" atributos que se correlacionan entre sí, ya que asume que cada `p(x|y)` evento es independiente, cuando no lo son.\n",
    "\n",
    "- Este algoritmo enfrenta el \"problema de frecuencia cero\" donde asigna probabilidad cero a una variable categórica cuya categoría en el conjunto de datos de prueba no estaba disponible en el conjunto de datos de entrenamiento. Sería mejor si usara una técnica de suavizado para superar este problema.\n",
    "- Sus estimaciones pueden ser incorrectas en algunos casos, por lo que no debe tomar muy en serio sus resultados de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Clasificadores Naive Bayes\n",
    "\n",
    "- El método *Multinomial Naive Bayes* es un enfoque de aprendizaje bayesiano común en el procesamiento del lenguaje natural. Usando el teorema de Bayes, el programa estima la etiqueta de un texto, como un correo electrónico o un artículo de periódico. Evalúa la probabilidad de cada etiqueta para una muestra determinada y devuelve la etiqueta con la posibilidad más alta.\n",
    "- El *Bernoulli Naive Bayes* es parte de la familia de Naive Bayes. Solo toma valores binarios. Puede haber varias características, pero se supone que cada una es una variable de valor binario (Bernoulli, booleano). Por lo tanto, esta clase requiere que las muestras se representen como vectores de características con valores binarios.\n",
    "- El *Gaussian Naive Bayes* gaussiano es una variante de Naive Bayes que sigue la distribución normal gaussiana y admite datos continuos. Para construir un modelo simple utilizando Gaussian Naive Bayes, asumimos que los datos se caracterizan por una distribución Gaussiana sin covarianza (dimensiones independientes) entre los parámetros. Este modelo puede ajustarse simplemente calculando la media y la desviación estándar de los puntos dentro de cada etiqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Gaussian Naive Bayes al Conjunto de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "print(iris_dataset['feature_names'])\n",
    "print(iris_dataset['data'][0:10,:])\n",
    "print(iris_dataset['target_names'])\n",
    "print(iris_dataset['target'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naiveBayes = GaussianNB()\n",
    "naiveBayes.fit(X_entrenamiento, y_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones conjunto de prueba:\n",
      " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "y_predict = naiveBayes.predict(X_prueba)\n",
    "print(\"Predicciones conjunto de prueba:\\n {}\".format(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado de la prueba: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayes.score(X_prueba, y_prueba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos con predicción erronea sobre el total 150 de los ejemplos : 6\n",
      "Resultado de la prueba: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión sobre todo el conjunto de datos\n",
    "y_pred = naiveBayes.fit(iris_dataset.data, iris_dataset.target).predict(iris_dataset.data)\n",
    "print(\"Número de ejemplos con predicción erronea sobre el total %d de los ejemplos : %d\"\n",
    "      % (iris_dataset.data.shape[0],(iris_dataset.target != y_pred).sum()))\n",
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayes.score(iris_dataset.data, iris_dataset.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333333, 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.86666667, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(naiveBayes, iris_dataset.data, iris_dataset.target, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.95 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas para evaluar el rendimiento de los clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "La matriz de confusión de una evaluación de clasificación binaria. Las etiquetas de clase en el conjunto de entrenamiento pueden tomar solo dos valores posibles, a los que normalmente podemos referirnos como positivo o negativo. Las instancias positivas y negativas que un clasificador predice correctamente se denominan positivos verdaderos (PV) y negativos verdaderos (NV), respectivamente. De forma similar, las instancias clasificadas incorrectamente se denominan falsos positivos (FP) y falsos negativos (FN). La matriz de confusión es simplemente una tabla que muestra el número de instancias que se encuentran bajo cada una de estas cuatro categorías.\n",
    "\n",
    "\n",
    "<img src=\"../figuras/matriz_de_confusion.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión, Recuperación y F1 Score\n",
    "\n",
    "Precisión: Proporción de todas las predicciones positivas que son correctas. La precisión es una medida de cuántas predicciones positivas fueron observaciones positivas reales\n",
    "\n",
    "$$Precisión = \\frac{PV}{PV + FP} = \\frac{positivos\\ predichos\\ correctamente}{todas\\ las\\ predicciones\\ positivas}$$\n",
    "\n",
    "Recuperación: Proporción de todas las observaciones positivas reales que son correctas. La recuperación es una medida de cuántas observaciones positivas reales se pronosticaron correctamente\n",
    "\n",
    "$$Recuperación = \\frac{PV}{PV + FN} = \\frac{predichos\\ de\\ ser\\ positivos}{todas\\ las\\ observaciones\\ positivas}$$\n",
    "\n",
    "Otra métrica relacionada que se usa con frecuencia es F1 Score, que tiene en cuenta la precisión y la recuperación. Es la media armónica de estas 2 métricas y se calcula como tal:\n",
    "\n",
    "$$F1 = 2\\times\\frac{precisión \\times recuperación}{precisión + recuperación}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión:\n",
      "            predice-setosa  predice-versicolor  predice-virginica\n",
      "actual                                                           \n",
      "setosa                  13                   0                  0\n",
      "versicolor               0                  16                  0\n",
      "virginica                0                   0                  9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, y_predict)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-setosa','predice-versicolor','predice-virginica'])\n",
    "skcm['actual'] = ['setosa','versicolor','virginica']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de la Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      1.00      1.00        16\n",
      "   virginica       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, y_predict, target_names=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Bernoulli Naive Bayes al Conjunto de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = iris_dataset['data']\n",
    "etiquetas = iris_dataset['target']\n",
    "\n",
    "# Para usar Bernoulli Naive Bayes es necesario normalizar los datos\n",
    "data = StandardScaler().fit_transform(data)\n",
    "X_BNB_entrenamiento, X_BNB_prueba, y_BNB_entrenamiento, y_BNB_prueba = train_test_split(data, etiquetas, random_state=0)\n",
    "naiveBayesBernoulli = BernoulliNB()\n",
    "naiveBayesBernoulli.fit(X_BNB_entrenamiento, y_BNB_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones conjunto de prueba:\n",
      " [1 1 0 2 0 2 0 2 2 2 2 2 2 2 2 0 2 1 0 0 1 1 0 0 2 0 0 2 0 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred_BNB = naiveBayesBernoulli.predict(X_BNB_prueba)\n",
    "print(\"Predicciones conjunto de prueba:\\n {}\".format(y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado de la prueba: 0.66\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayesBernoulli.score(X_BNB_prueba, y_BNB_prueba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos con predicción erronea sobre el total 150 de los ejemplos : 37\n",
      "Resultado de la prueba: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión sobre todo el conjunto de datos\n",
    "y_pred_BNB = naiveBayesBernoulli.fit(data, etiquetas).predict(data)\n",
    "print(\"Número de ejemplos con predicción erronea sobre el total %d de los ejemplos : %d\"\n",
    "      % (data.shape[0],(etiquetas != y_pred_BNB).sum()))\n",
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayesBernoulli.score(data, etiquetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.73333333, 0.66666667, 0.86666667, 0.6       ,\n",
       "       0.66666667, 0.86666667, 0.8       , 0.8       , 0.86666667])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_BNB = cross_val_score(naiveBayesBernoulli, data, etiquetas, cv=10)\n",
    "scores_BNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.75 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión: %0.2f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusión:\n",
      "            predice-setosa  predice-versicolor  predice-virginica\n",
      "actual                                                           \n",
      "setosa                  13                   0                  0\n",
      "versicolor               1                   5                 10\n",
      "virginica                0                   2                  7\n"
     ]
    }
   ],
   "source": [
    "y_predict_BNB = naiveBayesBernoulli.predict(X_BNB_prueba)\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, y_predict_BNB)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-setosa','predice-versicolor','predice-virginica'])\n",
    "skcm['actual'] = ['setosa','versicolor','virginica']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de la Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.93      1.00      0.96        13\n",
      "  versicolor       0.71      0.31      0.43        16\n",
      "   virginica       0.41      0.78      0.54         9\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.68      0.70      0.65        38\n",
      "weighted avg       0.72      0.66      0.64        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, y_predict_BNB, target_names=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de Correos Basura Usando un Clasificador Bayesiano Ingenuo (Naives Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un filtro de spam (correos basura) con una precisión bastante alta a partir de correos electrónicos reales etiquetados como `spam` (correos electrónicos basura) o `ham` (correos electrónicos que no son basura). Usando un conjunto de datos real. El conjunto de datos a utilizar es el [Enron-Spam](http://www.aueb.gr/users/ion/data/enron-spam/). Este conjunto de datos es de dominio publico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el conjunto de datos a un _Dataframe_ de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etiqueta</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: returned mail\\n\\na message sent by you could not be delivered .\\n\\nsubject : just to her . . .\\n\\nfrom :\\n\\nto :\\n\\nthe original message was received at 19 jul 2005 10 : 57 : 00 + 0100\\n\\nfrom ?\\n\\n- - - - - the following addresses had delivery problems - - - - -\\n\\n( permanent unrecoverable error )\\n\\ndiese e - mail enthält vertrauliche und / oder rechtlich geschützte\\n\\ninformatione...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: don ' t move ! ' and at\\n\\nthis notification was sent using automated system . please\\n\\nprocess to stop the auto - generated email .\\n\\nsat , 30 oct 2004 07 : 52 : 00 - 0600\\n\\na pprov a l account statement\\n\\nsecurity control number : 5351 - 3025 - 9032 - 1243\\n\\noffer expiration date : 11 / 17 / 04\\n\\ninterest ra t e : 3 . 8\\n\\nmaximum available amount : $ 300 , 000\\n\\ndescription ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: = ? gb 2312 ? q ? want _ to _ establish _ the _ office _ in _ china = 3 f ? =\\n\\nsetting up an office in china can be very difficult if you are not familiar with the chinese legislation and requirements of different authorities . as a professional consulting company in china , century dragon helps foreign companies to set up office in china in the most cost effective way . - starting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: start date : 1 / 27 / 02 ; hourahead hour : 21 ;\\n\\nstart date : 1 / 27 / 02 ; hourahead hour : 21 ; no ancillary schedules awarded . no variances detected .\\n\\nlog messages :\\n\\nparsing file - - &gt; &gt; o : \\ portland \\ westdesk \\ california scheduling \\ iso final schedules \\ 2002012721 . txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: nymex _ 1123 _ im . xls\\n\\nhere is the nymex initial margins as of statements dated 11 / 23 . total is $ 182 mm after credit lines .\\n\\ngreg 35399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: rto orders - grid south , se trans , spp and entergy\\n\\nthe southeast rto orders are out and have followed through with what we expected from the discussion at the ferc meeting .\\n\\nthe spp and entergy rto proposals have been rejected because they fail to satisfy the scope and configuration requirements of order no . 2000 . the commission notes that the required discussions between sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: california senate formally withdraws contempt actions against enron\\n\\nyesterday , we reached agreement with the senate regarding the terms and conditions under which the company would provide information to senator dunn ' s committee investigating wholesale price spikes .\\n\\nin return , dunn agreed to have is committee formally withdraw all contempt actions against enron .\\n\\nthis mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : metals - imminent actions - an update\\n\\nso what are the actions coming out of this ? just pushing it ( who don ' t seem\\n\\nto have the as 400 resources ) won ' t fix the problem . also , what is the plan\\n\\nre sap ?\\n\\nmike jordan @ ect\\n\\n02 / 26 / 2001 01 : 11 pm\\n\\nto : richard causey / corp / enron @ enron , rick buy / hou / ect @ ect , sally\\n\\nbeck / hou / ect @ ect\\n\\ncc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: e - commerce conference at berkeley , may 22\\n\\nany interest in this conference ?\\n\\nvince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: tw weekly report for march 22 , 2002\\n\\nattached is the tw weekly report for march 22 , 2002 .\\n\\njan moore\\n\\nx 53858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  etiqueta  \\\n",
       "0     spam   \n",
       "1     spam   \n",
       "2     spam   \n",
       "3      ham   \n",
       "4      ham   \n",
       "5      ham   \n",
       "6      ham   \n",
       "7      ham   \n",
       "8      ham   \n",
       "9      ham   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                             texto  \n",
       "0  Subject: returned mail\\n\\na message sent by you could not be delivered .\\n\\nsubject : just to her . . .\\n\\nfrom :\\n\\nto :\\n\\nthe original message was received at 19 jul 2005 10 : 57 : 00 + 0100\\n\\nfrom ?\\n\\n- - - - - the following addresses had delivery problems - - - - -\\n\\n( permanent unrecoverable error )\\n\\ndiese e - mail enthält vertrauliche und / oder rechtlich geschützte\\n\\ninformatione...  \n",
       "1  Subject: don ' t move ! ' and at\\n\\nthis notification was sent using automated system . please\\n\\nprocess to stop the auto - generated email .\\n\\nsat , 30 oct 2004 07 : 52 : 00 - 0600\\n\\na pprov a l account statement\\n\\nsecurity control number : 5351 - 3025 - 9032 - 1243\\n\\noffer expiration date : 11 / 17 / 04\\n\\ninterest ra t e : 3 . 8\\n\\nmaximum available amount : $ 300 , 000\\n\\ndescription ...  \n",
       "2  Subject: = ? gb 2312 ? q ? want _ to _ establish _ the _ office _ in _ china = 3 f ? =\\n\\nsetting up an office in china can be very difficult if you are not familiar with the chinese legislation and requirements of different authorities . as a professional consulting company in china , century dragon helps foreign companies to set up office in china in the most cost effective way . - starting ...  \n",
       "3                                                                                                      Subject: start date : 1 / 27 / 02 ; hourahead hour : 21 ;\\n\\nstart date : 1 / 27 / 02 ; hourahead hour : 21 ; no ancillary schedules awarded . no variances detected .\\n\\nlog messages :\\n\\nparsing file - - > > o : \\ portland \\ westdesk \\ california scheduling \\ iso final schedules \\ 2002012721 . txt  \n",
       "4                                                                                                                                                                                                                                                      Subject: nymex _ 1123 _ im . xls\\n\\nhere is the nymex initial margins as of statements dated 11 / 23 . total is $ 182 mm after credit lines .\\n\\ngreg 35399  \n",
       "5  Subject: rto orders - grid south , se trans , spp and entergy\\n\\nthe southeast rto orders are out and have followed through with what we expected from the discussion at the ferc meeting .\\n\\nthe spp and entergy rto proposals have been rejected because they fail to satisfy the scope and configuration requirements of order no . 2000 . the commission notes that the required discussions between sp...  \n",
       "6  Subject: california senate formally withdraws contempt actions against enron\\n\\nyesterday , we reached agreement with the senate regarding the terms and conditions under which the company would provide information to senator dunn ' s committee investigating wholesale price spikes .\\n\\nin return , dunn agreed to have is committee formally withdraw all contempt actions against enron .\\n\\nthis mo...  \n",
       "7  Subject: re : metals - imminent actions - an update\\n\\nso what are the actions coming out of this ? just pushing it ( who don ' t seem\\n\\nto have the as 400 resources ) won ' t fix the problem . also , what is the plan\\n\\nre sap ?\\n\\nmike jordan @ ect\\n\\n02 / 26 / 2001 01 : 11 pm\\n\\nto : richard causey / corp / enron @ enron , rick buy / hou / ect @ ect , sally\\n\\nbeck / hou / ect @ ect\\n\\ncc ...  \n",
       "8                                                                                                                                                                                                                                                                                                              Subject: e - commerce conference at berkeley , may 22\\n\\nany interest in this conference ?\\n\\nvince  \n",
       "9                                                                                                                                                                                                                                                                                  Subject: tw weekly report for march 22 , 2002\\n\\nattached is the tw weekly report for march 22 , 2002 .\\n\\njan moore\\n\\nx 53858  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron = pd.read_csv('../datos/enron_spam.csv.zip')\n",
    "pd.set_option('max_colwidth', 400)\n",
    "enron.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos entrenar un algoritmo para clasificar los correos electrónicos, necesitamos unos atributos (features). En la clasificación de documentos, la frecuencia con la que aparece cada palabra es un buen atributo.\n",
    "\n",
    "Vamos a crear una tabla con todas las palabras mencionadas en el corpus(colleción de correos electrónicos que tenemos) y su frecuencia en cada clase de correos electrónicos (spam o ham):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso se llama tokenización porque transformamos una colección de documentos de texto a una matriz de recuento de tokens. Con scikit-learn esto es muy fácil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Los emails que tenemos en el DataFrame.\n",
    "texto_correo = enron['texto'].values\n",
    "\n",
    "# Aprender el vocabulario del corpus\n",
    "# y extraer el recuento de tokens.\n",
    "atributos = count_vectorizer.fit_transform(texto_correo)\n",
    "\n",
    "# Las etiquetas (spam o ham).\n",
    "etiquetas = enron['etiqueta'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir los datos en un conjunto de entrenamiento y uno de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "        atributos, etiquetas,\n",
    "        train_size=0.8,\n",
    "        test_size=0.2,\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelo_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_bayes.fit(X_entrenamiento, y_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.99\n",
      "\n",
      "Matriz de confusión:\n",
      "        predice-ham  predice-spam\n",
      "actual                           \n",
      "ham            6539            70\n",
      "spam             68          6810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predecir etiquetas para los emails de testeo.\n",
    "prediccion_etiquetas = modelo_bayes.predict(X_prueba)\n",
    "\n",
    "# Calcular la precisión comparando\n",
    "# las etiquetas predecidas y las etiquedas reales.\n",
    "exactitud = accuracy_score(prediccion_etiquetas, y_prueba)\n",
    "\n",
    "print(\"Exactitud: %.2f\" % (exactitud))\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, prediccion_etiquetas)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-ham','predice-spam'])\n",
    "skcm['actual'] = ['ham', 'spam']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de la Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      6609\n",
      "        spam       0.99      0.99      0.99      6878\n",
      "\n",
      "    accuracy                           0.99     13487\n",
      "   macro avg       0.99      0.99      0.99     13487\n",
      "weighted avg       0.99      0.99      0.99     13487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, prediccion_etiquetas, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: ['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Correos de de prueba.\n",
    "correos_prueba = ['Free Viagra!',\n",
    "               \"I'm going to attend the meeting tomorrow.\"]\n",
    "\n",
    "# Tokenización.\n",
    "atributos_prueba = count_vectorizer.transform(correos_prueba)\n",
    "\n",
    "# Predecir etiquetas.\n",
    "prediccion = modelo_bayes.predict(atributos_prueba)\n",
    "\n",
    "print(\"Predicciones: %s\" % prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
