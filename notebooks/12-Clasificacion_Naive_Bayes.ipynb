{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Tema 2: Aprendizaje Supervisado</h1>\n",
    "    <br/>\n",
    "    <h1>Clasificador Bayesiano Ingenuo (Naive Bayes)</h1>\n",
    "    <br>\n",
    "    <h5>Prof. Wladimir Rodriguez</h5>\n",
    "    <h5>wladimir@ula.cve</h5>\n",
    "    <h5>Departamento de Computación</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "- Es un tipo de aprendizaje supervisado: Se conoce la clase verdadera de cada uno de los ejemplos que se utilizan para construir el clasificador\n",
    "- El problema de clasificación consiste en predecir una determinada clase (categórica) para un objeto\n",
    "- **La tarea de clasificación**: Dados un conjunto de ejemplos ya clasificados, construir un modelo o clasificador que permita clasificar nuevos casos\n",
    "- El problema fundamental de la clasificación está directamente relacionado con la separabilidad de las clases.\n",
    "\n",
    "### Clases linealmente separables\n",
    "\n",
    "<img src=\"../figuras/ClasificacionLineal.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "### Clases no linealmente separables\n",
    "\n",
    "<img src=\"../figuras/NoLinearSeparable.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Clasificación\n",
    "\n",
    "Estudiaremos algunos de los algoritmos de clasificación mas utilizados:\n",
    "\n",
    "+ Clasificador Bayesiano Ingenuo (Naive Bayes)\n",
    "+ Perceptrón Simple\n",
    "+ Regresión Logística\n",
    "+ Vecino más cercano\n",
    "+ Árboles de decisión\n",
    "+ Support vector machines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores Bayesianos Ingenuos (*Naive Bayes Classifiers*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes es un algoritmo de aprendizaje automático para problemas de clasificación. Esta basado en el teorema de probabilidad de Bayes. Se utiliza principalmente para la clasificación de texto la cual implica conjuntos de datos de entrenamiento con una alta dimensionalidad. Algunos ejemplos son filtración de correos basura, análisis de sentimiento y clasificación de artículos de noticias.\n",
    "\n",
    "No sólo es conocido por su simplicidad, sino también por su eficacia. Es rápido construir modelos y hacer predicciones con el algoritmo Naive Bayes. Naive Bayes es el primer algoritmo que debe ser considerado para resolver problemas de clasificación de texto. Por lo tanto, es importante aprender este algoritmo a fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es el algoritmo Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes es un algoritmo que aprende la probabilidad de que un objeto con ciertos atributos pertenesca a un grupo o una clase en particular. En resumen, es un clasificador probabilístico. ¿Por qué se llama así?\n",
    "\n",
    "El algoritmo Naive Bayes se llama \"ingenuo\" porque hace la suposición de que la ocurrencia de un atributo en particular es independiente de la ocurrencia de los otros atributos.\n",
    "\n",
    "Por ejemplo, si tratamos de identificar una fruta basada en su color, forma y sabor, entonces una fruta de color naranja, esférica y ácida sería muy probablemente una naranja. Incluso si estos atributos dependen unos de otros o de la presencia de las otros atributos, todas estos atributos contribuyen individualmente a la probabilidad de que esta fruta es una naranja y es por eso que se conoce como \"ingenuo\".\n",
    "\n",
    "En cuanto a la parte de \"Bayes\", se refiere al estadístico y filósofo, Thomas Bayes y el teorema que lleva su nombre, el teorema de Bayes, que es la base para el Algoritmo Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Matemáticas del Algoritmo Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base del algoritmo Naive Bayes es el Teorema de Bayes o también conocido como la Regla de Bayes o la Ley de Bayes. Nos da un método para calcular la probabilidad condicional, es decir, la probabilidad de un evento basado en conocimientos previos disponibles sobre los eventos. Más formalmente, el teorema de Bayes se expresa como la siguiente ecuación:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)\\times P(A)}{P(B)}$$\n",
    "\n",
    "Entendamos la declaración primero y luego examinaremos la prueba de la declaración. Los componentes de la declaración anterior son:\n",
    "\n",
    "- $P (A|B)$: Probabilidad (probabilidad condicional) de ocurrencia del evento A dado el evento B es verdadero\n",
    "- $P (A)$ y $P (B)$: Probabilidades de la ocurrencia del evento A y B respectivamente\n",
    "- $P (B | A)$: Probabilidad de la ocurrencia del evento B dado que el evento A es verdadero\n",
    "\n",
    "La terminología del método bayesiano de probabilidad (más comúnmente utilizada) es la siguiente:\n",
    "\n",
    "$$P(h|D) = \\frac{P(D|h)\\times P(h)}{P(D)}$$\n",
    "\n",
    "- $h$ se le denomina la hipótesis y a $D$ se le denomina la observación.\n",
    "- $P(h)$  Probabilidad de que la hipótesis `h` sea cierta o probabilidad a priori de la hipótesis `h`.\n",
    "- $P(D)$  Probabilidad de que recibamos la observación `D` o probabilidad a priori de la observación `D`.\n",
    "- $P(D|h)$  Probabilidad de observar el dato `D`, cuando se cumple la hipótesis `h` o probabilidad a posteriori de la observación `D`.\n",
    "- $P(h|D)$  Probabilidad de que se cumpla la hipótesis `h`, dado que se ha obtenido el dato `D`, o probabilidad a posteriori de la hipótesis `h`.\n",
    "\n",
    "\n",
    "Por lo que podemos reescribir el Teorema de Bayes como:\n",
    "\n",
    "$$Probabilidad\\ posterior\\ hipótesis = \\frac{(Verosimilitud)\\times (Probabilidad\\ previa\\ hipótesis)}{Probabilidad\\ previa\\ observación}$$\n",
    "\n",
    "En general estamos interesados en calcular el **decisor máximo a posteriori**:\n",
    "\n",
    "$$h_{MAP}=argmax_h\\ P(h|D) = argmax_h\\ \\frac{P(D|h)\\times P(h)}{P(D)}$$\n",
    "\n",
    "Dado que $P(D)$ es constante para todas las hipótesis, lo podemos eliminar\n",
    "\n",
    "$$h_{MAP}=argmax_h\\ P(h|D) = argmax_h\\ {P(D|h)\\times P(h)}$$\n",
    "\n",
    "En el caso de que todas las hipótesis sea equiprobables a priori. Se puede calcular el **decisor de máxima verosimilitud**:\n",
    "\n",
    "$$h_{ML}=argmax_h\\ P(D|h)$$\n",
    "\n",
    "**Tomemos un ejemplo para entender mejor el teorema de Bayes.**\n",
    "\n",
    "Supongamos que usted tiene que sacar una sola carta de una baraja estándar de 52 cartas. Ahora la probabilidad de que la carta sea una Reina es $P(Reina) = \\frac{4}{52} = \\frac{1}{13}$. Si se le da evidencia de que la carta que ha escogido es una carta con una persona, la probabilidad posterior $P(Reina | Persona)$ se puede calcular usando el teorema de Bayes como sigue:\n",
    "\n",
    "$$P(Reina|Persona) = \\frac{P(Persona|Reina)\\times P(Reina)}{P(Persona)}$$\n",
    "\n",
    "Ahora $P (Persona | Reina) = 1$ porque dada que la carta es una reina, es definitivamente una carta de una persona. Ya hemos calculado $P(Reina)$. El único valor que queda para calcular es $P(Persona)$, que es igual a $\\frac {3} {13}$ ya que hay tres cartas de personas para cada palo en una baraja. Por lo tanto,\n",
    "\n",
    "$$P(Reina|Persona) = 1 \\times \\frac{1}{13}\\times \\frac{13}{3}=\\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación usando Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un problema de clasificación de aprendizaje automático, hay varios atributos y clases, digamos, $C_1, C_2, \\ldots, C_k$. El objetivo principal del algoritmo Naive Bayes es calcular la probabilidad condicional de que un objeto con un vector de atributos $x_1, x_2, \\ldots, x_n$ pertenezca a una clase particular $C_i$,\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = \\frac{P(x_1, x_2, \\ldots, x_n|C_i)\\times P(C_i)}{P(x_1, x_2, \\ldots, x_n)}\\ para\\ 1 ≤ i ≤ k$$\n",
    "\n",
    "Dada la suposición de que los atributos son independientes podemos decir que:\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = (\\prod_{j=1}^{j=n}P(x_j|C_i))\\times \\frac{P(C_i)}{P(x_1, x_2, \\ldots, x_n)}\\ para\\ 1 ≤ i ≤ k$$\n",
    "\n",
    "La expresion $P(x_1, x_2, \\ldots, x_n)$ es constante para todas las clases, podemos entonces decir que\n",
    "\n",
    "$$P(C_i|x_1, x_2, \\ldots, x_n) = (\\prod_{j=1}^{j=n}P(x_j|C_i))\\times P(C_i)\\ para\\ 1 ≤ i ≤ k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo funciona el Algoritmo Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos aprendido cuál es el algoritmo Naive Bayes, cómo se relaciona el Teorema de Bayes con él y cuál es la expresión del Teorema de Bayes para este algoritmo. Tomemos un ejemplo simple la siguente tabla con ejemplos si debemos jugar al tenis bajo ciertas circunstancias. Éstas podrían ser el clima, la temperatura, la humedad y la fuerza del viento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos y convetir los valores categoricos en valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('../datos/temperatura.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir los valores no numéricos a valores numéricos\n",
    "\n",
    "Los algoritmos de aprendizaje automático solo pueden funcionar con valores numéricos, por lo que se hace necesario convertir aquellos valores no muméricos a numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for colname in datos.columns:\n",
    "    le.fit(datos[colname])\n",
    "    print(colname, le.classes_)\n",
    "    datos[colname] = le.transform(datos[colname])\n",
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de Ejemplos de la Clase Si\n",
    "Clase_Si = datos['Jugar_Tenis'][datos['Jugar_Tenis'] == 1].count()\n",
    "\n",
    "# Cantidad de Ejemplos de la Clase No\n",
    "Clase_No = datos['Jugar_Tenis'][datos['Jugar_Tenis'] == 0].count()\n",
    "\n",
    "# Total de ejemplos\n",
    "total = datos['Jugar_Tenis'].count()\n",
    "\n",
    "# Probabilidad de la Clase Si\n",
    "P_Si = Clase_Si/total\n",
    "\n",
    "# Probabilidad de la Clase No\n",
    "P_No = Clase_No/total\n",
    "\n",
    "print(\"Probabilidad de la Clase Si: \", P_Si)\n",
    "print(\"Probabilidad de la Clase No: \", P_No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = ['Lluvia', 'Nublado', 'Soleado', 'AltaT', 'BajaT',\n",
    "         'MediaT', 'AltaH', 'NormalH', 'Devil', 'Fuerte']\n",
    "\n",
    "columnas = ['Jugar_Si', 'Jugar_No']\n",
    "\n",
    "mapa_columnas = {'Lluvia':'Clima', 'Nublado':'Clima', 'Soleado':'Clima',\n",
    "                 'AltaT':'Temperatura', 'MediaT':'Temperatura','BajaT':'Temperatura',\n",
    "                 'AltaH':'Humedad', 'NormalH':'Humedad',\n",
    "                 'Devil':'Viento', 'Fuerte':'Viento'}\n",
    "\n",
    "mapa_valores = {'Lluvia':0, 'Nublado':1, 'Soleado':2,\n",
    "                 'AltaT':0, 'BajaT':2,'MediaT':1,\n",
    "                 'AltaH':0, 'NormalH':1,\n",
    "                 'Devil':0, 'Fuerte':1}\n",
    "\n",
    "cond_prob_df = pd.DataFrame( np.zeros([10,2]), columns = columnas, index =indice)\n",
    "cond_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, attr in enumerate(indice):\n",
    "    cond_prob_df.loc[attr, 'Jugar_Si'] = ((datos[mapa_columnas[attr]] == mapa_valores[attr]) & (datos['Jugar_Tenis'] == 1)).sum()/float(total)/float(P_Si)\n",
    "    cond_prob_df.loc[attr, 'Jugar_No'] = ((datos[mapa_columnas[attr]] == mapa_valores[attr]) & (datos['Jugar_Tenis'] == 0)).sum()/float(total)/float(P_No)\n",
    "cond_prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular las Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos1 = pd.read_csv('../datos/temperatura.csv')\n",
    "datos1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad de la Clase Si = 9/14\n",
    "\n",
    "Probabilidad de la Clase No = 5/14\n",
    "\n",
    "Para el atributo Clima:\n",
    "\n",
    "| Clima  | Jugar = Si | Jugar = No |\n",
    ":-----:|:--------: | :---------:\n",
    "|  Soleado  | 2/9 | 3/5 |\n",
    "| Nublado  | 4/9 | 0/5 |\n",
    "| Lluvia   | 3/9 | 2/5 |\n",
    "  \n",
    "\n",
    "Para el atributo Temperatura:\n",
    "\n",
    "Temperatura  | Jugar = Si | Jugar = No |\n",
    ":-----:|:--------: | :---------:\n",
    "  Alta  | 2/9 | 2/5\n",
    "  Media  | 4/9 | 2/5\n",
    "  Baja   | 3/9 | 1/5\n",
    "  \n",
    "  \n",
    "Para el atributo Humedad:\n",
    "\n",
    "Humedad  | Jugar = Si | Jugar = No |\n",
    "  :-----:|:--------: | :---------:\n",
    "  Alta  | 3/9 | 4/5\n",
    "  Normal  | 6/9 | 1/5\n",
    "  \n",
    "Para el atributo Viento:\n",
    "\n",
    "Viento  | Jugar = Si | Jugar = No |\n",
    "  :-----:|:--------: | :---------:\n",
    "  Fuerte  | 3/9 | 3/5\n",
    "  Débil  | 6/9 | 2/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad de Jugar si los atributos son: \n",
    "### Clima = Soleado, Temperatura = Baja, Humedad = Alta, Viento = Fuerte\n",
    "\n",
    "\n",
    "Probabilidad de Si = $\\frac{2}{9}\\times \\frac{3}{9}\\times \\frac{3}{9}\\times \\frac{3}{9}\\times \\frac{9}{14}$ = 0,0053\n",
    "\n",
    "Probabilidad de No = $\\frac{3}{5}\\times \\frac{1}{5}\\times \\frac{4}{5}\\times \\frac{3}{5}\\times \\frac{5}{14}$ = 0,0206\n",
    "\n",
    "La predicción es No\n",
    "\n",
    "Normalizando:\n",
    "\n",
    "Probabilidad de Si = $\\frac{0.0053}{0.0053+0.0206}$ = 0.205\n",
    "\n",
    "Probabilidad de No = $\\frac{0.0206}{0.0053+0.0206}$ = 0.795"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes con atributos continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_2 = pd.read_csv('../datos/temperatura_num.csv')\n",
    "datos_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular media y desviación estandar para cada calse de los atributos continuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo Temperatura:\n",
    "\n",
    "Temperatura, Jugar=Si | Temperatura, Jugar=No |\n",
    "  ------------- | -------------\n",
    "  28.3 | 28.4\n",
    "  21.1 | 26.7\n",
    "  20.0 | 18.3\n",
    "  17.8 | 22.2\n",
    "  20.6 | 21.7\n",
    "  23.9 |\n",
    "  23.9 |\n",
    "  22.2 |\n",
    "  27.2 |\n",
    "media: 22.8 | 23.7\n",
    "desviación estandar: 3.4 | 4.4\n",
    "\n",
    "Para el atributo Humedad:\n",
    "\n",
    "Humedad, Jugar=Si | Humedad, Jugar=No |\n",
    "  ------------- | -------------\n",
    "  86 | 85\n",
    "  96 | 90\n",
    "  80 | 70\n",
    "  65 | 95\n",
    "  70 | 91\n",
    "  80 |\n",
    "  70 |\n",
    "  90 |\n",
    "  75 |\n",
    "media: 79.1 | 86.2\n",
    "desviación estandar: 10.2 | 9.7\n",
    "\n",
    "\n",
    "Asumiendo que la distribución es normal se utiliza la siguiente formula para calcular la probabilidad de la evidencia dada la clase\n",
    "\n",
    "$$\n",
    "P(x_j|C_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{ij}}{e}^{-\\frac{(x_j-\\mu_{ij})^2}{2\\sigma_{ij}^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de la media de la temperatura usando pandas\n",
    "datos_2.groupby('Jugar')['Temperatura'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de la desviación estándar de la temperatura usando pandas\n",
    "datos_2.groupby('Jugar')['Temperatura'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de la media de la humedad usando pandas\n",
    "datos_2.groupby('Jugar')['Humedad'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de la desviación estándar de la humedad usando pandas\n",
    "datos_2.groupby('Jugar')['Humedad'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad de Jugar si los atributos son: \n",
    "### Clima = Soleado, Temperatura = 24, Humedad = 74, Viento = Fuerte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad de Temperatura = 24 y Jugar = Si\n",
    "\n",
    "$$\n",
    "P(Temperatura=24|Jugar = Si) = {\\frac{1}{\\sqrt{2\\pi}(3.4)}{e}^{-\\frac{(24-22.8)^2}{2(3.4)^2}}}=0.117\n",
    "$$\n",
    "\n",
    "Probabilidad de Temperatura = 24 y Jugar = No\n",
    "\n",
    "$$\n",
    "P(Temperatura=24|Jugar = No) = {\\frac{1}{\\sqrt{2\\pi}(4.4)}{e}^{-\\frac{(24-23.7)^2}{2(4.4)^2}}}=0.09\n",
    "$$\n",
    "\n",
    "Probabilidad de Humedad = 74 y Jugar = Si\n",
    "\n",
    "$$\n",
    "P(Humedad=74|Jugar = Si) = {\\frac{1}{\\sqrt{2\\pi}(10.2)}{e}^{-\\frac{(74-79.1)^2}{2(10.2)^2}}}=0.035\n",
    "$$\n",
    "\n",
    "Probabilidad de Humedad = 74 y Jugar = No\n",
    "\n",
    "$$\n",
    "P(Humedad=74|Jugar = No) = {\\frac{1}{\\sqrt{2\\pi}(9.7)}{e}^{-\\frac{(74-86.2)^2}{2(9.7)^2}}}=0.019\n",
    "$$\n",
    "\n",
    "\n",
    "Probabilidad de Si = $\\frac{2}{9}\\times 0.117\\times 0.035\\times \\frac{3}{9}\\times \\frac{9}{14}$ = 0,000195\n",
    "\n",
    "Probabilidad de No = $\\frac{3}{5}\\times 0.09\\times 0.019\\times \\frac{3}{5}\\times \\frac{5}{14}$ = 0,00022\n",
    "\n",
    "La predicción es No\n",
    "\n",
    "Normalizando:\n",
    "\n",
    "Probabilidad de Si = $\\frac{0,000195}{0,000195+0,00022}$ = 0.470\n",
    "\n",
    "Probabilidad de No = $\\frac{0.00022}{0,000195+0,00022}$ = 0.530"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventajas y desventajas de Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventajas:\n",
    "\n",
    "- Extremadamente rápido para entrenar / aplicar (solo contar cosas)\n",
    "- Bueno en la clasificación de documentos y el filtrado de correo basura.\n",
    "- Proporciona una predicción probabilística directa.\n",
    "- Naive Bayes tiene un costo de cálculo muy bajo.\n",
    "- Se puede utilizar con problemas de predicción de múltiples clases.\n",
    "- Es simple y fácil de implementar.\n",
    "- No requiere tantos datos de entrenamiento.\n",
    "- Maneja tanto datos continuos como discretos.\n",
    "- Es altamente escalable con la cantidad de predictores y puntos de datos.\n",
    "- Es rápido y se puede utilizar para hacer predicciones en tiempo real.\n",
    "- No es sensible a atributos irrelevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desventajas:\n",
    "\n",
    "- Naive Bayes asume que todos los predictores (o características) son independientes y rara vez suceden en la vida real. Esto limita la aplicabilidad de este algoritmo en casos de uso del mundo real.\n",
    "- Cuando el conjunto de atributos es grande (y escaso, como los atributos de palabras en la clasificación de texto) Bayes ingenuo podría \"contar dos veces\" atributos que se correlacionan entre sí, ya que asume que cada `p(x|y)` evento es independiente, cuando no lo son.\n",
    "\n",
    "- Este algoritmo enfrenta el \"problema de frecuencia cero\" donde asigna probabilidad cero a una variable categórica cuya categoría en el conjunto de datos de prueba no estaba disponible en el conjunto de datos de entrenamiento. Sería mejor si usara una técnica de suavizado para superar este problema.\n",
    "- Sus estimaciones pueden ser incorrectas en algunos casos, por lo que no debe tomar muy en serio sus resultados de probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Clasificadores Naive Bayes\n",
    "\n",
    "- El método *Multinomial Naive Bayes* es un enfoque de aprendizaje bayesiano común en el procesamiento del lenguaje natural. Usando el teorema de Bayes, el programa estima la etiqueta de un texto, como un correo electrónico o un artículo de periódico. Evalúa la probabilidad de cada etiqueta para una muestra determinada y devuelve la etiqueta con la posibilidad más alta.\n",
    "- El *Bernoulli Naive Bayes* es parte de la familia de Naive Bayes. Solo toma valores binarios. Puede haber varias características, pero se supone que cada una es una variable de valor binario (Bernoulli, booleano). Por lo tanto, esta clase requiere que las muestras se representen como vectores de características con valores binarios.\n",
    "- El *Gaussian Naive Bayes* gaussiano es una variante de Naive Bayes que sigue la distribución normal gaussiana y admite datos continuos. Para construir un modelo simple utilizando Gaussian Naive Bayes, asumimos que los datos se caracterizan por una distribución Gaussiana sin covarianza (dimensiones independientes) entre los parámetros. Este modelo puede ajustarse simplemente calculando la media y la desviación estándar de los puntos dentro de cada etiqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Gaussian Naive Bayes al Conjunto de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "print(iris_dataset['feature_names'])\n",
    "print(iris_dataset['data'][0:10,:])\n",
    "print(iris_dataset['target_names'])\n",
    "print(iris_dataset['target'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naiveBayes = GaussianNB()\n",
    "naiveBayes.fit(X_entrenamiento, y_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = naiveBayes.predict(X_prueba)\n",
    "print(\"Predicciones conjunto de prueba:\\n {}\".format(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayes.score(X_prueba, y_prueba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión sobre todo el conjunto de datos\n",
    "y_pred = naiveBayes.fit(iris_dataset.data, iris_dataset.target).predict(iris_dataset.data)\n",
    "print(\"Número de ejemplos con predicción erronea sobre el total %d de los ejemplos : %d\"\n",
    "      % (iris_dataset.data.shape[0],(iris_dataset.target != y_pred).sum()))\n",
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayes.score(iris_dataset.data, iris_dataset.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(naiveBayes, iris_dataset.data, iris_dataset.target, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas para evaluar el rendimiento de los clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "La matriz de confusión de una evaluación de clasificación binaria. Las etiquetas de clase en el conjunto de entrenamiento pueden tomar solo dos valores posibles, a los que normalmente podemos referirnos como positivo o negativo. Las instancias positivas y negativas que un clasificador predice correctamente se denominan positivos verdaderos (PV) y negativos verdaderos (NV), respectivamente. De forma similar, las instancias clasificadas incorrectamente se denominan falsos positivos (FP) y falsos negativos (FN). La matriz de confusión es simplemente una tabla que muestra el número de instancias que se encuentran bajo cada una de estas cuatro categorías.\n",
    "\n",
    "\n",
    "<img src=\"../figuras/matriz_de_confusion.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión, Recuperación y F1 Score\n",
    "\n",
    "Precisión: Proporción de todas las predicciones positivas que son correctas. La precisión es una medida de cuántas predicciones positivas fueron observaciones positivas reales\n",
    "\n",
    "$$Precisión = \\frac{PV}{PV + FP} = \\frac{positivos\\ predichos\\ correctamente}{todas\\ las\\ predicciones\\ positivas}$$\n",
    "\n",
    "Recuperación: Proporción de todas las observaciones positivas reales que son correctas. La recuperación es una medida de cuántas observaciones positivas reales se pronosticaron correctamente\n",
    "\n",
    "$$Recuperación = \\frac{PV}{PV + FN} = \\frac{predichos\\ de\\ ser\\ positivos}{todas\\ las\\ observaciones\\ positivas}$$\n",
    "\n",
    "Otra métrica relacionada que se usa con frecuencia es F1 Score, que tiene en cuenta la precisión y la recuperación. Es la media armónica de estas 2 métricas y se calcula como tal:\n",
    "\n",
    "$$F1 = 2\\times\\frac{precisión \\times recuperación}{precisión + recuperación}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, y_predict)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-setosa','predice-versicolor','predice-virginica'])\n",
    "skcm['actual'] = ['setosa','versicolor','virginica']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, y_predict, target_names=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar Bernoulli Naive Bayes al Conjunto de Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = iris_dataset['data']\n",
    "etiquetas = iris_dataset['target']\n",
    "\n",
    "# Para usar Bernoulli Naive Bayes es necesario normalizar los datos\n",
    "data = StandardScaler().fit_transform(data)\n",
    "X_BNB_entrenamiento, X_BNB_prueba, y_BNB_entrenamiento, y_BNB_prueba = train_test_split(data, etiquetas, random_state=0)\n",
    "naiveBayesBernoulli = BernoulliNB()\n",
    "naiveBayesBernoulli.fit(X_BNB_entrenamiento, y_BNB_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BNB = naiveBayesBernoulli.predict(X_BNB_prueba)\n",
    "print(\"Predicciones conjunto de prueba:\\n {}\".format(y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayesBernoulli.score(X_BNB_prueba, y_BNB_prueba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la precisión sobre todo el conjunto de datos\n",
    "y_pred_BNB = naiveBayesBernoulli.fit(data, etiquetas).predict(data)\n",
    "print(\"Número de ejemplos con predicción erronea sobre el total %d de los ejemplos : %d\"\n",
    "      % (data.shape[0],(etiquetas != y_pred_BNB).sum()))\n",
    "print(\"Resultado de la prueba: {:.2f}\".format(naiveBayesBernoulli.score(data, etiquetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_BNB = cross_val_score(naiveBayesBernoulli, data, etiquetas, cv=10)\n",
    "scores_BNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precisión: %0.2f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_BNB = naiveBayesBernoulli.predict(X_BNB_prueba)\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, y_predict_BNB)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-setosa','predice-versicolor','predice-virginica'])\n",
    "skcm['actual'] = ['setosa','versicolor','virginica']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, y_predict_BNB, target_names=['setosa', 'versicolor', 'virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de Correos Basura Usando un Clasificador Bayesiano Ingenuo (Naives Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un filtro de spam (correos basura) con una precisión bastante alta a partir de correos electrónicos reales etiquetados como `spam` (correos electrónicos basura) o `ham` (correos electrónicos que no son basura). Usando un conjunto de datos real. El conjunto de datos a utilizar es el [Enron-Spam](http://www.aueb.gr/users/ion/data/enron-spam/). Este conjunto de datos es de dominio publico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el conjunto de datos a un _Dataframe_ de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = pd.read_csv('../datos/enron_spam.csv.zip')\n",
    "pd.set_option('max_colwidth', 400)\n",
    "enron.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de que podamos entrenar un algoritmo para clasificar los correos electrónicos, necesitamos unos atributos (features). En la clasificación de documentos, la frecuencia con la que aparece cada palabra es un buen atributo.\n",
    "\n",
    "Vamos a crear una tabla con todas las palabras mencionadas en el corpus(colleción de correos electrónicos que tenemos) y su frecuencia en cada clase de correos electrónicos (spam o ham):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso se llama tokenización porque transformamos una colección de documentos de texto a una matriz de recuento de tokens. Con scikit-learn esto es muy fácil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Los emails que tenemos en el DataFrame.\n",
    "texto_correo = enron['texto'].values\n",
    "\n",
    "# Aprender el vocabulario del corpus\n",
    "# y extraer el recuento de tokens.\n",
    "atributos = count_vectorizer.fit_transform(texto_correo)\n",
    "\n",
    "# Las etiquetas (spam o ham).\n",
    "etiquetas = enron['etiqueta'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir los datos en un conjunto de entrenamiento y uno de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "        atributos, etiquetas,\n",
    "        train_size=0.8,\n",
    "        test_size=0.2,\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelo_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bayes.fit(X_entrenamiento, y_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predecir etiquetas para los emails de testeo.\n",
    "prediccion_etiquetas = modelo_bayes.predict(X_prueba)\n",
    "\n",
    "# Calcular la precisión comparando\n",
    "# las etiquetas predecidas y las etiquedas reales.\n",
    "exactitud = accuracy_score(prediccion_etiquetas, y_prueba)\n",
    "\n",
    "print(\"Exactitud: %.2f\" % (exactitud))\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "skcm = confusion_matrix(y_prueba, prediccion_etiquetas)\n",
    "# colocar en un dataframe para imprimir las etiquetas\n",
    "skcm = pd.DataFrame(skcm, columns=['predice-ham','predice-spam'])\n",
    "skcm['actual'] = ['ham', 'spam']\n",
    "skcm = skcm.set_index('actual')\n",
    "print(skcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nReporte de la Clasificación:\")\n",
    "print(classification_report(y_prueba, prediccion_etiquetas, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correos de de prueba.\n",
    "correos_prueba = ['Free Viagra!',\n",
    "               \"I'm going to attend the meeting tomorrow.\"]\n",
    "\n",
    "# Tokenización.\n",
    "atributos_prueba = count_vectorizer.transform(correos_prueba)\n",
    "\n",
    "# Predecir etiquetas.\n",
    "prediccion = modelo_bayes.predict(atributos_prueba)\n",
    "\n",
    "print(\"Predicciones: %s\" % prediccion)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
